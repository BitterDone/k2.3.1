[2019-11-24 21:45:33,792] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 21:45:33,800] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:45:33,800] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:45:33,800] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:45:33,801] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 21:45:33,814] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 21:45:33,815] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 21:45:33,827] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,827] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,827] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,828] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,828] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,828] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,830] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\sbt\bin;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,832] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,832] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,833] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,892] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,893] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,894] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:33,941] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 21:45:33,945] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 21:45:33,949] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 21:45:35,079] INFO starting (kafka.server.KafkaServer)
[2019-11-24 21:45:35,080] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 21:45:35,114] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:45:35,118] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,118] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,118] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,119] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,119] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,119] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,121] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files (x86)\sbt\bin;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,124] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,124] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,125] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,126] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,126] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,127] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,128] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,128] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,130] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@47f9738 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:45:35,146] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:45:35,149] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:45:35,152] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:45:35,154] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52474 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 21:45:35,157] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52474 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:35,158] INFO Creating new log file: log.31e (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 21:45:35,216] INFO Established session 0x1001f41b8680000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52474 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:45:35,218] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f41b8680000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:45:35,221] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:45:35,311] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x1 zxid:0x31f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,349] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x2 zxid:0x320 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,381] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x3 zxid:0x321 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,772] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x4 zxid:0x322 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,814] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x5 zxid:0x323 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,848] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x6 zxid:0x324 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,888] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x7 zxid:0x325 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,926] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x8 zxid:0x326 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:35,965] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0x9 zxid:0x327 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:36,001] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0xa zxid:0x328 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:36,040] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0xb zxid:0x329 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:36,067] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0xc zxid:0x32a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:36,107] INFO Got user-level KeeperException when processing sessionid:0x1001f41b8680000 type:create cxid:0xd zxid:0x32b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:45:36,410] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 21:45:36,560] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:45:36,571] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:45:36,606] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:45:36,606] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:45:36,608] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:45:36,681] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 21:45:36,864] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:36,865] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,299] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:37,424] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,425] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:37,435] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 619 ms (kafka.log.Log)
[2019-11-24 21:45:37,483] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,484] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,501] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:37,559] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,560] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:37,561] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 117 ms (kafka.log.Log)
[2019-11-24 21:45:37,586] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,586] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,665] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,666] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 103 ms (kafka.log.Log)
[2019-11-24 21:45:37,696] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,697] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,761] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,765] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 96 ms (kafka.log.Log)
[2019-11-24 21:45:37,781] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,782] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,840] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,842] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 21:45:37,851] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,852] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,923] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,925] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 21:45:37,938] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:37,938] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:37,997] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,001] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-11-24 21:45:38,024] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,025] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,089] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,090] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-11-24 21:45:38,119] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,120] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,139] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:38,193] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,194] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:38,194] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 102 ms (kafka.log.Log)
[2019-11-24 21:45:38,225] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,231] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,325] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,326] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 130 ms (kafka.log.Log)
[2019-11-24 21:45:38,347] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,347] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,370] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:38,431] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,432] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:38,433] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 105 ms (kafka.log.Log)
[2019-11-24 21:45:38,457] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,458] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,524] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,525] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 90 ms (kafka.log.Log)
[2019-11-24 21:45:38,555] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,557] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,651] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,652] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 126 ms (kafka.log.Log)
[2019-11-24 21:45:38,667] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,667] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,721] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,722] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 21:45:38,740] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,740] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,793] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,795] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 21:45:38,800] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,801] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,865] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,866] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 21:45:38,893] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,893] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,950] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:38,954] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-11-24 21:45:38,970] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:38,972] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,031] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,032] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 21:45:39,042] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,042] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,092] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,093] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 21:45:39,103] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,104] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,166] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,170] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-11-24 21:45:39,187] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,188] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,245] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,247] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 21:45:39,257] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,257] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,318] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,320] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-11-24 21:45:39,328] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,328] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,347] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:39,400] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,401] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:39,401] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-11-24 21:45:39,404] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,405] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,483] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,485] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-11-24 21:45:39,513] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,513] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,604] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,605] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 117 ms (kafka.log.Log)
[2019-11-24 21:45:39,632] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,632] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,700] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,705] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 99 ms (kafka.log.Log)
[2019-11-24 21:45:39,733] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,733] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,770] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:39,836] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,836] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:39,837] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 123 ms (kafka.log.Log)
[2019-11-24 21:45:39,866] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,867] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,940] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:39,941] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 103 ms (kafka.log.Log)
[2019-11-24 21:45:39,950] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:39,950] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,012] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,014] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-11-24 21:45:40,032] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:40,032] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,049] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:45:40,106] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,107] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:45:40,107] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 91 ms (kafka.log.Log)
[2019-11-24 21:45:40,139] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:40,140] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,200] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,201] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-11-24 21:45:40,206] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:45:40,206] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:45:40,227] WARN Exception causing close of session 0x1001f41b8680000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 21:45:40,229] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52474 which had sessionid 0x1001f41b8680000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 21:57:23,467] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 21:57:23,470] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:57:23,471] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:57:23,471] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 21:57:23,472] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 21:57:23,494] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 21:57:23,496] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 21:57:23,512] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,513] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,513] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,514] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,514] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,514] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,519] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,525] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,536] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,536] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,536] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,538] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,539] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,539] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,539] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,561] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,561] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,562] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:23,589] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 21:57:23,593] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 21:57:23,769] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 21:57:24,419] INFO starting (kafka.server.KafkaServer)
[2019-11-24 21:57:24,422] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 21:57:24,467] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:24,475] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,475] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,475] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,476] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,476] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,476] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,479] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,484] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,485] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,486] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,486] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,486] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,487] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,487] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,487] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,490] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:24,534] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:24,538] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:24,544] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:24,546] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52547 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 21:57:24,555] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52547 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:24,557] INFO Creating new log file: log.32c (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 21:57:24,594] INFO Established session 0x1001f4c89bf0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52547 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:24,596] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f4c89bf0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:24,600] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:24,644] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x1 zxid:0x32d txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,692] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x2 zxid:0x32e txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,719] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x3 zxid:0x32f txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,757] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x4 zxid:0x330 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,788] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x5 zxid:0x331 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,823] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x6 zxid:0x332 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,851] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x7 zxid:0x333 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,890] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x8 zxid:0x334 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,918] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0x9 zxid:0x335 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,956] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0xa zxid:0x336 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:24,984] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0xb zxid:0x337 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:25,022] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0xc zxid:0x338 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:25,052] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:create cxid:0xd zxid:0x339 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:25,203] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 21:57:25,267] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:57:25,281] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:57:25,321] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:25,321] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:25,334] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:25,371] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 21:57:25,436] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:25,438] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:25,787] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:25,874] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:25,876] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:25,889] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 479 ms (kafka.log.Log)
[2019-11-24 21:57:25,908] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:25,932] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:25,947] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,008] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,010] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,011] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 106 ms (kafka.log.Log)
[2019-11-24 21:57:26,018] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,019] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,036] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,038] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-24 21:57:26,043] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,044] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,058] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,060] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-24 21:57:26,074] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,074] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,088] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,090] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-24 21:57:26,094] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,094] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,108] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,109] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 21:57:26,114] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,115] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,129] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,131] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 21:57:26,134] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,135] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,146] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,147] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 21:57:26,152] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,152] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,164] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,234] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,236] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,236] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 86 ms (kafka.log.Log)
[2019-11-24 21:57:26,240] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,241] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,253] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,254] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 21:57:26,259] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,260] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,273] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,338] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,339] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,340] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2019-11-24 21:57:26,344] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,345] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,356] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,356] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 21:57:26,361] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,361] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,373] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,375] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 21:57:26,380] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,380] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,391] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,393] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 21:57:26,398] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,398] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,411] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,412] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 21:57:26,416] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,416] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,430] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,432] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 21:57:26,437] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,438] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,452] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,453] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 21:57:26,456] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,456] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,470] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,471] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 21:57:26,474] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,475] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,487] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,489] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 21:57:26,494] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,495] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,509] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,511] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-24 21:57:26,515] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,517] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,529] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,530] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 21:57:26,534] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,534] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,545] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,546] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 21:57:26,551] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,551] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,563] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,630] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,631] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,632] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 84 ms (kafka.log.Log)
[2019-11-24 21:57:26,634] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,635] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,645] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,647] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 21:57:26,649] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,657] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,670] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,671] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-24 21:57:26,673] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,674] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,686] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,687] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 21:57:26,690] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,691] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,703] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,767] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,768] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,769] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 81 ms (kafka.log.Log)
[2019-11-24 21:57:26,771] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,772] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,783] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,784] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 21:57:26,787] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,787] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,800] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,801] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 21:57:26,805] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,805] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,816] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,880] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,881] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,882] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 79 ms (kafka.log.Log)
[2019-11-24 21:57:26,885] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,885] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,897] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,898] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 21:57:26,901] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:26,901] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,922] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,977] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:26,978] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:26,979] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 80 ms (kafka.log.Log)
[2019-11-24 21:57:27,018] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,019] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,142] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,144] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 163 ms (kafka.log.Log)
[2019-11-24 21:57:27,160] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,160] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,236] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,237] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-24 21:57:27,249] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,249] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,308] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,309] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 21:57:27,326] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,326] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,380] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,381] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 21:57:27,416] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,416] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,473] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,474] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-11-24 21:57:27,490] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,490] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,556] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,557] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-11-24 21:57:27,567] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,568] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,649] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,650] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-11-24 21:57:27,666] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,667] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,732] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,733] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 21:57:27,744] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,745] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,804] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,805] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 21:57:27,821] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,822] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,875] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,876] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 21:57:27,886] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,887] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,947] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:27,948] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 21:57:27,963] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:27,963] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,030] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,031] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-11-24 21:57:28,052] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,052] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,113] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,114] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 21:57:28,135] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,135] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,184] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,185] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 21:57:28,201] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,201] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,245] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,246] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 21:57:28,259] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,260] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,316] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,317] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 21:57:28,337] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,337] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,400] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,401] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-11-24 21:57:28,415] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,415] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,488] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,489] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 87 ms (kafka.log.Log)
[2019-11-24 21:57:28,502] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 21:57:28,502] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,570] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:28,571] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 21:57:28,574] INFO Logs loading complete in 3203 ms. (kafka.log.LogManager)
[2019-11-24 21:57:28,607] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 21:57:28,608] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 21:57:28,921] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 21:57:28,983] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 21:57:28,985] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 21:57:29,069] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,071] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,071] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,071] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,086] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 21:57:29,223] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 21:57:29,234] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0000 type:multi cxid:0x16 zxid:0x33a txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/0 Error:KeeperErrorCode = NodeExists for /brokers/ids/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:29,263] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72085301334245376' does not match current session '72092007626899456' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2019-11-24 21:57:29,268] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:122)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1784)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1722)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1689)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:97)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:262)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-24 21:57:29,271] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 21:57:29,272] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-24 21:57:29,279] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-24 21:57:29,285] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-24 21:57:29,285] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 21:57:29,286] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 21:57:29,286] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 21:57:29,286] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-24 21:57:29,288] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-24 21:57:29,288] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 21:57:29,288] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 21:57:29,289] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,474] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,474] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,476] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,672] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,672] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,673] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,677] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,677] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,677] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,875] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,875] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:29,878] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-24 21:57:29,879] INFO Shutting down. (kafka.log.LogManager)
[2019-11-24 21:57:31,013] INFO Expiring session 0x10019331b8e0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:31,014] INFO Expiring session 0x1001f41b8680000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:31,015] INFO Processed session termination for sessionid: 0x10019331b8e0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:31,017] INFO Processed session termination for sessionid: 0x1001f41b8680000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:31,329] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-24 21:57:31,329] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:31,332] INFO Processed session termination for sessionid: 0x1001f4c89bf0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:31,364] INFO Session: 0x1001f4c89bf0000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:31,365] INFO EventThread shut down for session: 0x1001f4c89bf0000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:31,366] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:31,366] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52547 which had sessionid 0x1001f4c89bf0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 21:57:31,366] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,328] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,328] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,331] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,338] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,338] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:32,339] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:33,339] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:33,339] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:33,341] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-24 21:57:33,362] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-24 21:57:33,367] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-24 21:57:33,367] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-24 21:57:33,370] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 21:57:47,439] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 21:57:47,864] INFO starting (kafka.server.KafkaServer)
[2019-11-24 21:57:47,865] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 21:57:47,884] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:47,889] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,889] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,889] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,891] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,892] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,892] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,894] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,898] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,899] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,899] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,900] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,901] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,901] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,901] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,902] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,903] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 21:57:47,919] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:47,922] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:47,924] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52590 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 21:57:47,925] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:47,927] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:47,959] INFO Established session 0x1001f4c89bf0001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 21:57:47,961] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f4c89bf0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 21:57:47,964] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 21:57:47,988] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x1 zxid:0x33f txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,028] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x2 zxid:0x340 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,069] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x3 zxid:0x341 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,098] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x4 zxid:0x342 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,129] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x5 zxid:0x343 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,163] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x6 zxid:0x344 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,202] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x7 zxid:0x345 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,230] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x8 zxid:0x346 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,258] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0x9 zxid:0x347 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,296] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0xa zxid:0x348 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,325] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0xb zxid:0x349 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,363] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0xc zxid:0x34a txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,391] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:create cxid:0xd zxid:0x34b txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:48,533] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 21:57:48,581] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:57:48,594] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 21:57:48,621] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:48,621] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:48,622] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 21:57:48,651] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 21:57:48,779] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:48,789] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:48,801] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 125 ms (kafka.log.Log)
[2019-11-24 21:57:49,171] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,172] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,173] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 362 ms (kafka.log.Log)
[2019-11-24 21:57:49,178] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,179] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,184] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,185] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,189] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,190] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,196] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,197] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,202] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,203] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,208] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,209] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,288] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,289] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,290] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 79 ms (kafka.log.Log)
[2019-11-24 21:57:49,295] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,296] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,360] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,362] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,363] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-11-24 21:57:49,368] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,368] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,373] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,373] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,378] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,378] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,383] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,383] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,388] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,389] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,393] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,394] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,398] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,399] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,403] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,404] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,408] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,408] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,414] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,414] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,420] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,421] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,487] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,488] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,488] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 65 ms (kafka.log.Log)
[2019-11-24 21:57:49,492] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,493] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,497] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,497] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,501] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,502] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,548] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,549] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,550] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 9 in 46 ms (kafka.log.Log)
[2019-11-24 21:57:49,554] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,555] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,558] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,559] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,608] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,609] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,610] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 50 ms (kafka.log.Log)
[2019-11-24 21:57:49,615] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,616] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,670] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,670] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 21:57:49,670] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 7 in 53 ms (kafka.log.Log)
[2019-11-24 21:57:49,674] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,674] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2019-11-24 21:57:49,678] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,679] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,683] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,684] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,688] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,688] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,692] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,692] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,696] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,697] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,703] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,703] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,707] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,708] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,711] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,711] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 21:57:49,715] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,716] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,721] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,722] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,726] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,727] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,731] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,732] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,736] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,737] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 21:57:49,740] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,741] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,744] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,745] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,749] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,749] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,753] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,754] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 21:57:49,757] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 21:57:49,758] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 21:57:49,760] INFO Logs loading complete in 1109 ms. (kafka.log.LogManager)
[2019-11-24 21:57:49,772] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 21:57:49,773] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 21:57:49,997] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 21:57:50,033] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 21:57:50,035] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 21:57:50,053] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,055] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,055] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,056] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,067] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 21:57:50,105] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 21:57:50,161] INFO Stat of the created znode at /brokers/ids/0 is: 844,844,1574654270110,1574654270110,1,0,0,72092007626899457,200,0,844
 (kafka.zk.KafkaZkClient)
[2019-11-24 21:57:50,162] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 844 (kafka.zk.KafkaZkClient)
[2019-11-24 21:57:50,220] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,223] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,223] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 21:57:50,280] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:50,282] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:50,287] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:50,337] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:23000,blockEndProducerId:23999) by writing to Zk with path version 24 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 21:57:50,362] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 21:57:50,363] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 21:57:50,363] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 21:57:50,415] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 21:57:50,443] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 21:57:50,448] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 21:57:50,448] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 21:57:50,449] INFO Kafka startTimeMs: 1574654270444 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 21:57:50,451] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 21:57:50,455] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0001 type:multi cxid:0x67 zxid:0x34f txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 21:57:50,556] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 21:57:50,579] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 21:57:50,582] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,595] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,596] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,636] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,637] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,697] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,698] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,745] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,745] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,803] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,812] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,877] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,880] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:50,959] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:50,961] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,025] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,026] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,080] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,081] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,131] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,131] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,191] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,191] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,241] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,241] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,291] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 21:57:51,291] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,295] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 7 (kafka.cluster.Replica)
[2019-11-24 21:57:51,296] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 7. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,299] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,299] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,352] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,352] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,402] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,402] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,440] INFO Replica loaded for partition testTopicName-0 with initial high watermark 26111 (kafka.cluster.Replica)
[2019-11-24 21:57:51,441] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 26111. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,445] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,445] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,502] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,502] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,561] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,562] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,925] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,925] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:51,991] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:51,991] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,041] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,041] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,102] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,103] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,153] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,153] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,201] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,201] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,251] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,251] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,311] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,311] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,360] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,361] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,422] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,423] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,461] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 21:57:52,461] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,467] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 21:57:52,468] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,472] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,472] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,521] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 9 (kafka.cluster.Replica)
[2019-11-24 21:57:52,521] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,524] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,525] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,582] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,582] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,642] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,643] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,723] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 1 (kafka.cluster.Replica)
[2019-11-24 21:57:52,724] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,727] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,727] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,774] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,774] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,813] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,813] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,864] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,864] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,923] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,924] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:52,990] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:52,990] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,051] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:53,051] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,424] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:53,425] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,474] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:53,474] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,523] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:53,523] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,562] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 21:57:53,562] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 21:57:53,614] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,616] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,617] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,618] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,618] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,619] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,619] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,620] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,621] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,622] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,622] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,623] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,623] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,623] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,624] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,625] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,626] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,628] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,628] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 12 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,630] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,630] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,631] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,632] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,633] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,634] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,636] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,637] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,638] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,638] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,639] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,639] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,640] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,641] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,642] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,642] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,643] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,643] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,653] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-19809 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,711] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 81 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,718] INFO [GroupCoordinator 0]: Loading group metadata for test-consumer-group with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,718] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,723] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-92282 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,727] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,727] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,728] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,728] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,730] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,735] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,742] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,747] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-12871 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,748] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,748] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,749] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,749] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,753] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-85740 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,753] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,754] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,754] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,755] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,755] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,756] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,759] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-14956 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,760] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,761] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,763] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,764] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 21:57:53,822] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-39607 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-1-aef7b750-5ad3-414e-af20-12642b849503 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,827] INFO [GroupCoordinator 0]: Stabilized group console-consumer-39607 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:57:53,836] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-39607 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:58:03,713] INFO [GroupCoordinator 0]: Member consumer-1-c5acf48c-9480-49e9-a9ad-a223566c828c in group console-consumer-19809 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:58:03,715] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-19809 in state PreparingRebalance with old generation 1 (__consumer_offsets-28) (reason: removing member consumer-1-c5acf48c-9480-49e9-a9ad-a223566c828c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 21:58:03,716] INFO [GroupCoordinator 0]: Group console-consumer-19809 with generation 2 is now empty (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:00:43,834] INFO [GroupMetadataManager brokerId=0] Group console-consumer-92282 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,840] INFO [GroupMetadataManager brokerId=0] Group console-consumer-85740 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,841] INFO [GroupMetadataManager brokerId=0] Group console-consumer-12871 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,842] INFO [GroupMetadataManager brokerId=0] Group console-consumer-14956 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,858] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Rolled new log segment at offset 7 in 11 ms. (kafka.log.Log)
[2019-11-24 22:00:43,859] INFO [GroupMetadataManager brokerId=0] Group console-consumer-19809 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,861] INFO [GroupMetadataManager brokerId=0] Group test-consumer-group transitioned to Dead in generation 7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:00:43,873] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Rolled new log segment at offset 9 in 11 ms. (kafka.log.Log)
[2019-11-24 22:00:43,874] INFO [GroupCoordinator 0]: Removed 1 offsets associated with deleted partitions: testTopicName-0. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:00:43,877] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:00:43,878] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:00:43,881] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:00:43,881] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:00:43,937] ERROR Error while renaming dir for testTopicName-0 in log dir D:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.262d87b0887846d58fad12b6a2c23125-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:784)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2085)
	at kafka.log.Log.renameDir(Log.scala:782)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:858)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:374)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:368)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:368)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:398)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:396)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:219)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:118)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.262d87b0887846d58fad12b6a2c23125-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 17 more
[2019-11-24 22:00:43,941] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:00:43,944] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:00:43,945] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:00:43,958] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:00:43,959] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:00:43,961] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:00:44,303] WARN Exception causing close of session 0x1001f4c89bf0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:00:44,306] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52590 which had sessionid 0x1001f4c89bf0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:00:52,012] INFO Expiring session 0x1001f4c89bf0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:00:52,012] INFO Processed session termination for sessionid: 0x1001f4c89bf0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,192] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:02:48,603] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:02:48,604] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:02:48,621] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:48,625] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,625] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,626] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,626] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,627] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,627] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,630] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,632] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,633] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,635] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,635] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,636] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,636] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,636] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,637] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,639] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:48,654] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:48,656] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:48,659] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52810 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:02:48,659] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:48,661] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52810 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:02:48,731] INFO Established session 0x1001f4c89bf0002 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52810 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:02:48,732] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f4c89bf0002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:48,735] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:48,758] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x1 zxid:0x355 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,797] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x2 zxid:0x356 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,830] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x3 zxid:0x357 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,869] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x4 zxid:0x358 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,900] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x5 zxid:0x359 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,935] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x6 zxid:0x35a txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:48,963] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x7 zxid:0x35b txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,002] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x8 zxid:0x35c txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,029] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0x9 zxid:0x35d txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,068] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0xa zxid:0x35e txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,096] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0xb zxid:0x35f txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,134] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0xc zxid:0x360 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,161] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0002 type:create cxid:0xd zxid:0x361 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:49,288] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 22:02:49,292] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:02:49,334] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:02:49,347] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:02:49,370] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:49,372] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:49,370] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:49,402] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:02:49,447] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:49,449] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:49,755] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:49,824] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:49,825] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:49,835] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 412 ms (kafka.log.Log)
[2019-11-24 22:02:49,844] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:49,845] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:49,856] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:49,917] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:49,918] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:49,919] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 77 ms (kafka.log.Log)
[2019-11-24 22:02:49,925] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:49,925] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:49,999] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,006] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-11-24 22:02:50,010] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,011] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,093] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,094] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-11-24 22:02:50,098] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,099] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,181] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,183] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 86 ms (kafka.log.Log)
[2019-11-24 22:02:50,187] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,187] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,242] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,243] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:50,247] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,247] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,324] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,326] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 22:02:50,329] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,330] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,385] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,386] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:50,391] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,391] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,401] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:50,447] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,448] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:50,449] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:50,453] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,453] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,506] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,508] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:02:50,512] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,512] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,522] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:50,590] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,591] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:50,591] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-24 22:02:50,595] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,595] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,650] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,651] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:50,654] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,655] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,711] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,712] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:02:50,715] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,716] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,771] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,773] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:02:50,777] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,777] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,854] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,855] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 22:02:50,858] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,859] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,915] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,916] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:02:50,919] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,920] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,975] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:50,976] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:50,980] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:50,981] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,036] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,038] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:51,041] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,041] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,096] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,097] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:51,100] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,100] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,158] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,159] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:02:51,162] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,162] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,438] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,440] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 280 ms (kafka.log.Log)
[2019-11-24 22:02:51,443] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,444] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,669] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,670] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 229 ms (kafka.log.Log)
[2019-11-24 22:02:51,674] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,674] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,684] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:51,741] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,742] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:51,744] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 72 ms (kafka.log.Log)
[2019-11-24 22:02:51,748] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,748] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,813] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,814] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:02:51,817] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,818] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,864] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,868] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 52 ms (kafka.log.Log)
[2019-11-24 22:02:51,873] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,874] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,934] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,936] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-24 22:02:51,940] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:51,940] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,951] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:51,953] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:02:51,953] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:51,954] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:51,962] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,018] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,020] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,022] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 11 in 85 ms (kafka.log.Log)
[2019-11-24 22:02:52,026] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,027] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,088] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,089] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-24 22:02:52,092] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,092] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,150] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,151] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:02:52,154] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,154] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,162] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,213] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,216] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,218] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 66 ms (kafka.log.Log)
[2019-11-24 22:02:52,224] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,225] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,282] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,283] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:02:52,288] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,288] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,298] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,299] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 7 (kafka.log.Log)
[2019-11-24 22:02:52,300] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,301] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,310] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,364] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,365] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:52,366] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 8 in 81 ms (kafka.log.Log)
[2019-11-24 22:02:52,369] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,370] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,425] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,426] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:02:52,429] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,429] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,486] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,487] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:52,490] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,490] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,536] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,537] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-24 22:02:52,540] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,541] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,596] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,597] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:02:52,599] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,599] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,657] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,658] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:52,661] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,661] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,718] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,719] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:52,721] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,722] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,888] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:52,889] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 169 ms (kafka.log.Log)
[2019-11-24 22:02:52,892] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:52,893] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,120] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,121] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 230 ms (kafka.log.Log)
[2019-11-24 22:02:53,124] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,124] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,196] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,197] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-11-24 22:02:53,200] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,200] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,258] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,258] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:53,261] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,262] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,271] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:02:53,318] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,319] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:02:53,320] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 61 ms (kafka.log.Log)
[2019-11-24 22:02:53,322] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,322] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,396] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,397] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-11-24 22:02:53,399] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,399] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,457] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,458] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:53,460] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,460] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,520] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,523] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-24 22:02:53,530] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,530] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,589] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,590] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-24 22:02:53,592] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,593] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,652] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,655] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-24 22:02:53,662] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,663] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,722] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,724] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-24 22:02:53,726] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,727] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,781] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,782] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:02:53,786] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:53,786] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,843] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:02:53,844] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:02:53,847] INFO Logs loading complete in 4444 ms. (kafka.log.LogManager)
[2019-11-24 22:02:53,856] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:02:53,856] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:02:54,068] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:02:54,083] ERROR Failed to clean up log for __consumer_offsets-36 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2036)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-24 22:02:54,098] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:02:54,099] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:02:54,123] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:02:54,127] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:02:54,127] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:02:54,129] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:02:54,142] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:02:54,145] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:02:54,150] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:02:54,151] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:02:54,153] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:02:54,496] WARN Exception causing close of session 0x1001f4c89bf0002: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:02:54,497] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52810 which had sessionid 0x1001f4c89bf0002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:02:58,730] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:02:59,157] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:02:59,159] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:02:59,175] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:59,179] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,179] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,180] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,180] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,181] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,181] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,184] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,186] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,186] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,189] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,189] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,190] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,190] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,190] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,190] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,192] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:02:59,206] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:59,210] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:59,213] INFO Accepted socket connection from /127.0.0.1:52836 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:02:59,214] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:59,217] INFO Client attempting to establish new session at /127.0.0.1:52836 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:02:59,264] INFO Established session 0x1001f4c89bf0003 with negotiated timeout 6000 for client /127.0.0.1:52836 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:02:59,265] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f4c89bf0003, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:02:59,268] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:02:59,291] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x1 zxid:0x363 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,331] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x2 zxid:0x364 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,364] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x3 zxid:0x365 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,402] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x4 zxid:0x366 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,434] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x5 zxid:0x367 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,468] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x6 zxid:0x368 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,498] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x7 zxid:0x369 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,535] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x8 zxid:0x36a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,563] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0x9 zxid:0x36b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,590] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0xa zxid:0x36c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,618] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0xb zxid:0x36d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,657] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0xc zxid:0x36e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,684] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0003 type:create cxid:0xd zxid:0x36f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:02:59,811] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 22:02:59,814] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:02:59,859] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:02:59,869] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:02:59,895] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:59,895] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:59,897] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:02:59,925] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:02:59,966] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:02:59,967] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,281] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,357] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,359] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,368] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 422 ms (kafka.log.Log)
[2019-11-24 22:03:00,380] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,380] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,392] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,449] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,450] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,451] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-11-24 22:03:00,455] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,455] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,467] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,468] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:00,479] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,479] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,490] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,492] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:03:00,497] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,497] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,507] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,509] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,516] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,517] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,528] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,529] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,533] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,534] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,549] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,550] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 22:03:00,554] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,554] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,566] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,567] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:00,571] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,571] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,583] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,642] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,643] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,644] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 75 ms (kafka.log.Log)
[2019-11-24 22:03:00,649] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,649] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,659] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,660] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:00,665] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,665] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,674] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,725] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,726] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,727] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 64 ms (kafka.log.Log)
[2019-11-24 22:03:00,730] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,731] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,740] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,741] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:00,744] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,745] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,755] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,756] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:00,760] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,760] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,771] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,772] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,777] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,777] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,790] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,791] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:03:00,794] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,794] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,805] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,806] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,810] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,811] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,828] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,829] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:03:00,833] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,834] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,844] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,845] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:00,849] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,849] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,859] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,860] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:00,864] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,865] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,874] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,876] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,881] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,882] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,891] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,892] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:00,896] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,897] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,908] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,909] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:00,914] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,915] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,924] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,994] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:00,995] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:00,996] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 85 ms (kafka.log.Log)
[2019-11-24 22:03:00,999] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:00,999] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,009] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,010] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,012] INFO Expiring session 0x1001f4c89bf0002, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:03:01,013] INFO Processed session termination for sessionid: 0x1001f4c89bf0002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:01,016] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,017] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,029] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,030] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:03:01,035] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,035] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,046] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,047] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,052] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,053] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,064] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,065] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:03:01,066] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,067] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,075] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,139] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,140] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,141] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 11 in 92 ms (kafka.log.Log)
[2019-11-24 22:03:01,145] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,146] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,156] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,157] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,161] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,161] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,170] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,171] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,174] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,175] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,186] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,231] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,233] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,234] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2019-11-24 22:03:01,237] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,237] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,248] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,249] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,252] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:03:01,253] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index (kafka.log.Log)
[2019-11-24 22:03:01,255] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:03:01,255] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:03:01,256] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:03:01,258] ERROR [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-24 22:03:01,259] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,269] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,271] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,271] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,283] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,284] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 7 (kafka.log.Log)
[2019-11-24 22:03:01,285] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,286] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,294] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,358] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,360] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,360] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 8 in 109 ms (kafka.log.Log)
[2019-11-24 22:03:01,363] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,363] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,373] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,374] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,377] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,377] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,387] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,388] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,391] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,392] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,402] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,403] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,406] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,406] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,418] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,419] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:01,422] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,423] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,433] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,434] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,437] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,437] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,448] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,449] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,451] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,452] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,463] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,464] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,466] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,466] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,478] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,479] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,481] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,481] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,491] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,493] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,496] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,496] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,507] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,508] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,511] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,512] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,523] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,584] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,585] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:01,586] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 77 ms (kafka.log.Log)
[2019-11-24 22:03:01,589] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,589] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,598] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,599] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:01,602] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,602] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,613] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,614] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,617] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,617] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,627] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,628] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,631] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,631] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,641] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,642] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:01,646] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,646] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,657] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,659] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:01,661] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,661] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,671] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,672] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:01,676] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,676] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,687] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,688] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,690] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:01,691] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,702] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:01,703] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:01,707] INFO Logs loading complete in 1781 ms. (kafka.log.LogManager)
[2019-11-24 22:03:01,717] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:03:01,718] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:03:01,925] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:03:01,941] ERROR Failed to clean up log for __consumer_offsets-36 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2036)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-24 22:03:01,949] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:03:01,950] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:03:01,972] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:01,973] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:01,976] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:01,973] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:01,991] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:03:01,992] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:03:01,997] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:03:01,997] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:03:02,000] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:03:02,338] WARN Exception causing close of session 0x1001f4c89bf0003: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:03:02,339] INFO Closed socket connection for client /127.0.0.1:52836 which had sessionid 0x1001f4c89bf0003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:03:10,012] INFO Expiring session 0x1001f4c89bf0003, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:03:10,012] INFO Processed session termination for sessionid: 0x1001f4c89bf0003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:17,702] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:03:18,129] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:03:18,131] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:03:18,148] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:03:18,152] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,153] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,153] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,154] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,155] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,155] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,160] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,164] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,164] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,165] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,165] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,165] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,166] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,166] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,167] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,168] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:03:18,183] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:03:18,188] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:03:18,190] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:52874 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:03:18,191] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:03:18,193] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:52874 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:03:18,311] INFO Established session 0x1001f4c89bf0004 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:52874 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:03:18,312] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f4c89bf0004, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:03:18,314] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:03:18,339] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x1 zxid:0x373 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,377] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x2 zxid:0x374 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,411] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x3 zxid:0x375 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,448] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x4 zxid:0x376 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,495] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x5 zxid:0x377 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,525] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x6 zxid:0x378 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,554] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x7 zxid:0x379 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,592] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x8 zxid:0x37a txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,620] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0x9 zxid:0x37b txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,648] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0xa zxid:0x37c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,687] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0xb zxid:0x37d txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,714] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0xc zxid:0x37e txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,752] INFO Got user-level KeeperException when processing sessionid:0x1001f4c89bf0004 type:create cxid:0xd zxid:0x37f txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:03:18,882] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 22:03:18,885] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:03:18,929] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:03:18,942] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:03:18,970] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:03:18,970] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:03:18,972] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:03:19,000] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:03:19,042] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,044] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,353] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,425] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,426] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,435] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 413 ms (kafka.log.Log)
[2019-11-24 22:03:19,444] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,445] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,457] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,507] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,508] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,508] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 66 ms (kafka.log.Log)
[2019-11-24 22:03:19,513] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,513] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,525] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,526] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:19,538] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,538] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,552] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,554] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-24 22:03:19,558] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,559] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,569] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,571] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,575] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,575] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,586] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,587] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,591] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,592] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,603] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,604] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,608] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,609] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,619] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,621] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,625] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,625] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,635] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,711] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,712] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,712] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 89 ms (kafka.log.Log)
[2019-11-24 22:03:19,716] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,717] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,726] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,728] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,732] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,732] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,744] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,806] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,811] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:19,814] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 84 ms (kafka.log.Log)
[2019-11-24 22:03:19,827] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,828] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,845] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,847] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-24 22:03:19,853] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,853] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,863] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,864] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:19,869] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,869] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,880] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,881] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:19,885] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,886] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,897] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,898] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:19,902] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,903] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,912] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,913] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:19,917] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,918] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,930] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,931] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:03:19,935] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,935] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,945] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,946] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:19,950] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,951] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,962] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,963] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:19,965] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,966] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,976] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,977] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:19,981] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,981] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,991] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:19,993] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:19,995] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:19,996] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,008] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,009] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:20,014] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,015] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,029] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,085] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,086] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,087] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 76 ms (kafka.log.Log)
[2019-11-24 22:03:20,090] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,090] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,101] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,102] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,106] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,107] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,132] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,133] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 28 ms (kafka.log.Log)
[2019-11-24 22:03:20,138] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,138] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,149] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,150] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,156] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,156] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,169] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,171] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:03:20,171] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,172] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,180] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,261] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,262] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,263] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 11 in 110 ms (kafka.log.Log)
[2019-11-24 22:03:20,266] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,266] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,276] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,277] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,280] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,280] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,293] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,294] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:20,297] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,297] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,307] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,356] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,357] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,357] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 62 ms (kafka.log.Log)
[2019-11-24 22:03:20,360] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,360] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,370] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,370] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-24 22:03:20,374] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:03:20,374] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index (kafka.log.Log)
[2019-11-24 22:03:20,375] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:03:20,375] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:03:20,376] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:03:20,378] ERROR [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-24 22:03:20,379] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,390] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,392] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,393] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,403] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,404] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 7 (kafka.log.Log)
[2019-11-24 22:03:20,405] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,407] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,414] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,470] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,471] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,473] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 8 in 102 ms (kafka.log.Log)
[2019-11-24 22:03:20,476] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,476] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,486] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,487] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:20,489] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,490] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,501] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,502] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,504] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,505] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,515] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,516] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,520] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,520] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,531] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,533] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,535] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,537] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,547] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,548] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,551] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,552] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,564] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,565] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:03:20,567] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,568] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,578] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,579] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,582] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,582] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,593] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,594] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,597] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,597] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,607] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,609] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,612] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,612] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,623] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,624] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,627] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,627] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,637] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,686] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,687] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:03:20,688] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 63 ms (kafka.log.Log)
[2019-11-24 22:03:20,690] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,690] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,700] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,701] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:20,703] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,703] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,714] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,714] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:20,717] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,717] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,728] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,729] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:03:20,731] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,732] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,742] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,742] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:20,745] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,745] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,756] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,757] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 13 ms (kafka.log.Log)
[2019-11-24 22:03:20,759] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,759] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,769] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,770] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:03:20,772] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,773] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,784] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,786] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:03:20,789] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:03:20,789] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,802] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:03:20,803] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:03:20,806] INFO Logs loading complete in 1805 ms. (kafka.log.LogManager)
[2019-11-24 22:03:20,814] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:03:20,815] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:03:21,053] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:03:21,075] ERROR Failed to clean up log for __consumer_offsets-36 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2036)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-24 22:03:21,076] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:03:21,082] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:03:21,107] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:21,108] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:21,109] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:21,108] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:03:21,122] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:03:21,123] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:03:21,127] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:03:21,128] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:03:21,131] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:03:21,471] WARN Exception causing close of session 0x1001f4c89bf0004: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:03:21,472] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:52874 which had sessionid 0x1001f4c89bf0004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:03:28,013] INFO Expiring session 0x1001f4c89bf0004, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:03:28,013] INFO Processed session termination for sessionid: 0x1001f4c89bf0004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:14,131] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:04:14,135] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:04:14,136] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:04:14,136] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:04:14,137] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:04:14,154] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:04:14,155] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:04:14,167] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,167] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,167] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,168] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,168] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,169] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,173] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,180] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,180] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,181] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,181] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,181] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,181] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,181] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,182] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,196] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,196] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,197] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:14,231] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:04:14,236] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:04:14,370] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:04:15,024] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:04:15,025] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:04:15,046] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:04:15,053] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,053] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,054] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,054] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,054] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,054] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,057] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,063] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,063] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,064] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,064] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,064] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,065] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,065] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,065] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,066] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:04:15,087] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:04:15,090] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:04:15,093] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:04:15,093] INFO Accepted socket connection from /127.0.0.1:52954 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:04:15,103] INFO Client attempting to establish new session at /127.0.0.1:52954 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:15,104] INFO Creating new log file: log.381 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:04:15,164] INFO Established session 0x1001f52cdca0000 with negotiated timeout 6000 for client /127.0.0.1:52954 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:15,172] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f52cdca0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:04:15,179] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:04:15,228] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x1 zxid:0x382 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,294] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x2 zxid:0x383 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,330] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x3 zxid:0x384 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,361] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x4 zxid:0x385 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,421] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x5 zxid:0x386 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,446] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x6 zxid:0x387 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,484] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x7 zxid:0x388 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,515] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x8 zxid:0x389 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,553] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0x9 zxid:0x38a txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,580] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0xa zxid:0x38b txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,619] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0xb zxid:0x38c txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,645] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0xc zxid:0x38d txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,684] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0000 type:create cxid:0xd zxid:0x38e txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:04:15,821] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 22:04:15,830] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:04:15,887] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:04:15,917] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:04:15,963] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:04:15,963] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:04:15,967] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:04:16,012] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:04:16,085] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:16,088] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,455] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 26111 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:16,534] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 26111 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,536] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000026111.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:16,548] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 26111 in 497 ms (kafka.log.Log)
[2019-11-24 22:04:16,564] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:16,564] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,587] INFO [ProducerStateManager partition=__consumer_offsets-0] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:16,906] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,909] INFO [ProducerStateManager partition=__consumer_offsets-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-0\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:16,910] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 349 ms (kafka.log.Log)
[2019-11-24 22:04:16,915] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:16,924] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,940] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,942] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2019-11-24 22:04:16,967] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:16,967] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,994] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:16,995] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-24 22:04:17,014] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,051] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,068] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,069] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:04:17,073] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,074] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,085] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,086] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:17,091] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,091] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,104] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,105] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:17,110] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,110] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,122] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,123] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:17,128] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,128] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,141] INFO [ProducerStateManager partition=__consumer_offsets-15] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,207] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,208] INFO [ProducerStateManager partition=__consumer_offsets-15] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-15\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,209] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 84 ms (kafka.log.Log)
[2019-11-24 22:04:17,212] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,212] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,223] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,225] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:17,229] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,230] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,242] INFO [ProducerStateManager partition=__consumer_offsets-17] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,300] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,301] INFO [ProducerStateManager partition=__consumer_offsets-17] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-17\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,302] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 75 ms (kafka.log.Log)
[2019-11-24 22:04:17,305] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,306] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,317] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,318] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:17,323] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,323] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,341] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,342] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:04:17,348] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,348] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,364] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,366] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:04:17,373] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,373] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,388] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,389] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 22:04:17,394] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,394] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,409] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,410] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 22:04:17,413] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,414] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,426] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,427] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:17,433] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,433] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,445] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,446] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:17,451] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,451] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,467] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,468] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 20 ms (kafka.log.Log)
[2019-11-24 22:04:17,473] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,474] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,486] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,487] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:17,490] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,491] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,505] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,507] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 18 ms (kafka.log.Log)
[2019-11-24 22:04:17,510] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,510] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,533] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,534] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 26 ms (kafka.log.Log)
[2019-11-24 22:04:17,538] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,538] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,549] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,614] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,615] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-28\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,616] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 80 ms (kafka.log.Log)
[2019-11-24 22:04:17,619] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,619] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,629] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,631] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:17,634] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,635] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,645] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,646] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:17,650] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,651] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,664] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,665] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:04:17,672] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,673] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,686] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,689] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:04:17,689] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,690] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,701] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,763] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 11 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,765] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000011.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,767] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 11 in 100 ms (kafka.log.Log)
[2019-11-24 22:04:17,770] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,771] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,783] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,785] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:17,789] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,789] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,806] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,808] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:04:17,811] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,811] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,825] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,868] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,869] INFO [ProducerStateManager partition=__consumer_offsets-34] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-34\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,870] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 61 ms (kafka.log.Log)
[2019-11-24 22:04:17,872] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,873] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,884] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,886] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:17,888] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:04:17,889] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.index (kafka.log.Log)
[2019-11-24 22:04:17,890] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Found file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log.swap from interrupted swap operation. (kafka.log.Log)
[2019-11-24 22:04:17,890] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix  for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:04:17,891] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Deleting index files with suffix .swap for baseFile D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log (kafka.log.Log)
[2019-11-24 22:04:17,894] ERROR [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-24 22:04:17,895] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,908] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,910] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:17,911] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,924] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,925] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 7 (kafka.log.Log)
[2019-11-24 22:04:17,925] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 7 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,926] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000007.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,938] INFO [ProducerStateManager partition=__consumer_offsets-36] Writing producer snapshot at offset 8 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,994] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 8 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:17,995] INFO [ProducerStateManager partition=__consumer_offsets-36] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000008.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:17,996] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 2 segments, log start offset 0 and log end offset 8 in 109 ms (kafka.log.Log)
[2019-11-24 22:04:18,000] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,002] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,013] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,017] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-24 22:04:18,023] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,024] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,038] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,039] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-24 22:04:18,042] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,042] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,055] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,056] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:18,059] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,059] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,079] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,080] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-24 22:04:18,084] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,085] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,097] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,099] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:04:18,103] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,104] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,114] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,115] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:18,119] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,120] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,130] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,131] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:18,137] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,138] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,148] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,149] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:18,153] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,154] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,166] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,168] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:04:18,172] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,173] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,185] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,186] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:18,190] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,190] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,201] INFO [ProducerStateManager partition=__consumer_offsets-46] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:04:18,253] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,254] INFO [ProducerStateManager partition=__consumer_offsets-46] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-46\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:04:18,255] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 68 ms (kafka.log.Log)
[2019-11-24 22:04:18,257] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,257] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,269] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,270] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:18,273] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,273] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,284] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,285] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:18,289] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,290] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,301] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,303] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 16 ms (kafka.log.Log)
[2019-11-24 22:04:18,307] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,307] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,319] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,320] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:18,324] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,324] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,336] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,337] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:04:18,340] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,341] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,352] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,353] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:18,356] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,356] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,368] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,369] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:04:18,373] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:04:18,373] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,387] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:04:18,388] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:04:18,391] INFO Logs loading complete in 2378 ms. (kafka.log.LogManager)
[2019-11-24 22:04:18,401] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:04:18,403] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:04:18,624] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:04:18,642] ERROR Failed to clean up log for __consumer_offsets-36 in dir D:\tmp\kafka-logs due to IOException (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.$anonfun$replaceSegments$4(Log.scala:2036)
	at kafka.log.Log.$anonfun$replaceSegments$4$adapted(Log.scala:2036)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Log.replaceSegments(Log.scala:2036)
	at kafka.log.Cleaner.cleanSegments(LogCleaner.scala:602)
	at kafka.log.Cleaner.$anonfun$doClean$6(LogCleaner.scala:528)
	at kafka.log.Cleaner.$anonfun$doClean$6$adapted(LogCleaner.scala:527)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.Cleaner.doClean(LogCleaner.scala:527)
	at kafka.log.Cleaner.clean(LogCleaner.scala:501)
	at kafka.log.LogCleaner$CleanerThread.cleanLog(LogCleaner.scala:359)
	at kafka.log.LogCleaner$CleanerThread.cleanFilthiestLog(LogCleaner.scala:328)
	at kafka.log.LogCleaner$CleanerThread.doWork(LogCleaner.scala:307)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:89)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.cleaned -> D:\tmp\kafka-logs\__consumer_offsets-36\00000000000000000000.timeindex.swap: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 16 more
[2019-11-24 22:04:18,655] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:04:18,656] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:04:18,685] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:04:18,686] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:04:18,688] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:04:18,689] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:04:18,701] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:04:18,702] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:04:18,708] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions  and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:04:18,709] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:04:18,711] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:04:19,055] WARN Exception causing close of session 0x1001f52cdca0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:04:19,057] INFO Closed socket connection for client /127.0.0.1:52954 which had sessionid 0x1001f52cdca0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:04:25,012] INFO Expiring session 0x1001f52cdca0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:04:25,013] INFO Processed session termination for sessionid: 0x1001f52cdca0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:29,550] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:05:29,982] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:05:29,984] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:05:30,004] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:05:30,008] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,018] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,020] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,038] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,042] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,043] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,072] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,087] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,101] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,114] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,115] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,117] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,134] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,149] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,152] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,154] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:05:30,195] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:05:30,199] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:05:30,202] INFO Accepted socket connection from /127.0.0.1:53058 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:05:30,203] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:05:30,208] INFO Client attempting to establish new session at /127.0.0.1:53058 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:05:30,355] INFO Established session 0x1001f52cdca0001 with negotiated timeout 6000 for client /127.0.0.1:53058 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:05:30,359] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f52cdca0001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:05:30,364] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:05:30,402] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x1 zxid:0x391 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,445] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x2 zxid:0x392 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,476] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x3 zxid:0x393 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,515] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x4 zxid:0x394 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,547] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x5 zxid:0x395 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,581] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x6 zxid:0x396 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,609] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x7 zxid:0x397 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,647] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x8 zxid:0x398 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,676] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0x9 zxid:0x399 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,713] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0xa zxid:0x39a txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,742] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0xb zxid:0x39b txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,781] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0xc zxid:0x39c txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,809] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:create cxid:0xd zxid:0x39d txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:30,956] INFO Cluster ID = 4XZ5zLAwT1KvcQBv9_47DA (kafka.server.KafkaServer)
[2019-11-24 22:05:30,961] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:05:31,024] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:05:31,042] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:05:31,083] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:05:31,084] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:05:31,103] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:05:31,142] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:05:31,153] INFO Logs loading complete in 10 ms. (kafka.log.LogManager)
[2019-11-24 22:05:31,169] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:05:31,174] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:05:31,470] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:05:31,508] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:05:31,511] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:05:31,536] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,549] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,549] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,549] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,576] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:05:31,620] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:05:31,675] INFO Stat of the created znode at /brokers/ids/0 is: 926,926,1574654731631,1574654731631,1,0,0,72092034538274817,200,0,926
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:05:31,676] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 926 (kafka.zk.KafkaZkClient)
[2019-11-24 22:05:31,684] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:05:31,799] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,802] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,802] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:05:31,825] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:31,828] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:31,841] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:31,893] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:24000,blockEndProducerId:24999) by writing to Zk with path version 25 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:05:31,925] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:05:31,927] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:05:31,931] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:05:31,994] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:05:32,018] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:05:32,032] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:05:32,032] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:05:32,033] INFO Kafka startTimeMs: 1574654732022 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:05:32,038] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:05:32,166] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:05:32,223] INFO Got user-level KeeperException when processing sessionid:0x1001f52cdca0001 type:multi cxid:0x6a zxid:0x3a2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:05:32,279] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,288] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:05:32,291] INFO Created log for partition __consumer_offsets-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,299] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-11-24 22:05:32,300] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,313] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:32,404] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,406] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:32,408] INFO Created log for partition __consumer_offsets-29 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,421] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-11-24 22:05:32,432] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,450] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:32,574] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,580] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:05:32,583] INFO Created log for partition __consumer_offsets-48 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,587] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-11-24 22:05:32,593] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,599] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:32,683] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,684] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:32,687] INFO Created log for partition __consumer_offsets-10 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,696] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-11-24 22:05:32,699] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,718] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:32,846] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,849] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-24 22:05:32,851] INFO Created log for partition __consumer_offsets-45 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,855] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-11-24 22:05:32,862] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,866] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:32,971] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:32,973] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:32,975] INFO Created log for partition __consumer_offsets-26 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:32,984] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-11-24 22:05:32,985] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:32,991] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,058] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,061] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-24 22:05:33,075] INFO Created log for partition __consumer_offsets-7 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,077] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-11-24 22:05:33,078] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,092] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,177] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,178] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:33,181] INFO Created log for partition __consumer_offsets-42 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,191] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-11-24 22:05:33,194] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,200] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,263] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,265] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:33,267] INFO Created log for partition __consumer_offsets-4 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,278] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-11-24 22:05:33,281] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,296] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,365] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,367] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:33,370] INFO Created log for partition __consumer_offsets-23 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,382] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-11-24 22:05:33,408] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,410] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,497] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,498] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:33,500] INFO Created log for partition __consumer_offsets-1 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,502] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,508] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,512] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,584] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,586] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:33,594] INFO Created log for partition __consumer_offsets-20 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,596] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-11-24 22:05:33,602] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,602] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,676] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,678] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:33,681] INFO Created log for partition __consumer_offsets-39 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,692] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-11-24 22:05:33,696] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,719] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,817] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,818] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:33,820] INFO Created log for partition __consumer_offsets-17 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,831] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-11-24 22:05:33,834] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,856] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:33,936] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:33,938] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:33,942] INFO Created log for partition __consumer_offsets-36 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:33,943] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-11-24 22:05:33,949] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:33,951] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,031] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,032] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:34,034] INFO Created log for partition __consumer_offsets-14 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,035] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-11-24 22:05:34,044] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,047] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,126] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,128] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:34,129] INFO Created log for partition __consumer_offsets-33 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,131] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-11-24 22:05:34,137] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,139] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,210] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,212] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-24 22:05:34,215] INFO Created log for partition __consumer_offsets-49 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,226] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-11-24 22:05:34,237] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,238] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,316] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,318] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:34,332] INFO Created log for partition __consumer_offsets-11 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,334] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-11-24 22:05:34,334] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,358] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,434] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,437] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-24 22:05:34,439] INFO Created log for partition __consumer_offsets-30 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,441] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-11-24 22:05:34,449] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,463] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,545] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,546] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:34,549] INFO Created log for partition __consumer_offsets-46 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,550] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-11-24 22:05:34,560] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,564] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,623] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,625] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:34,629] INFO Created log for partition __consumer_offsets-27 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,639] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-11-24 22:05:34,648] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,648] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,715] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,717] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:34,720] INFO Created log for partition __consumer_offsets-8 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,728] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-11-24 22:05:34,732] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,733] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,823] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,824] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:34,826] INFO Created log for partition __consumer_offsets-24 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,832] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-11-24 22:05:34,832] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,833] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,908] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:34,909] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:34,912] INFO Created log for partition __consumer_offsets-43 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:34,917] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-11-24 22:05:34,917] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:34,918] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:34,999] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,000] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:35,002] INFO Created log for partition __consumer_offsets-5 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,009] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-11-24 22:05:35,010] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,015] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,101] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,103] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:35,107] INFO Created log for partition __consumer_offsets-21 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,108] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-11-24 22:05:35,115] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,120] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,222] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,224] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-24 22:05:35,225] INFO Created log for partition __consumer_offsets-2 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,227] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-11-24 22:05:35,231] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,232] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,308] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,309] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:35,311] INFO Created log for partition __consumer_offsets-40 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,312] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-11-24 22:05:35,317] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,318] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,386] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,388] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:35,390] INFO Created log for partition __consumer_offsets-37 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,397] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-11-24 22:05:35,400] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,401] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,497] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,499] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:35,501] INFO Created log for partition __consumer_offsets-18 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,502] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-11-24 22:05:35,513] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,516] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,585] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,587] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:35,588] INFO Created log for partition __consumer_offsets-34 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,589] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-11-24 22:05:35,594] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,595] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,671] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,674] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-24 22:05:35,676] INFO Created log for partition __consumer_offsets-15 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,685] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-11-24 22:05:35,689] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,698] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,781] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,782] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:35,784] INFO Created log for partition __consumer_offsets-12 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,785] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-11-24 22:05:35,794] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,798] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,872] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,874] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:35,878] INFO Created log for partition __consumer_offsets-31 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,879] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-11-24 22:05:35,884] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,885] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:35,963] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:35,963] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:35,965] INFO Created log for partition __consumer_offsets-9 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:35,974] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-11-24 22:05:35,976] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:35,982] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,047] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,048] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:36,049] INFO Created log for partition __consumer_offsets-47 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,050] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-11-24 22:05:36,062] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,065] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,137] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,138] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:36,140] INFO Created log for partition __consumer_offsets-19 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,143] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-11-24 22:05:36,148] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,151] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,224] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,225] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:36,227] INFO Created log for partition __consumer_offsets-28 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,234] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-11-24 22:05:36,239] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,241] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,346] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,348] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:36,351] INFO Created log for partition __consumer_offsets-38 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,362] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-11-24 22:05:36,367] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,382] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,459] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,460] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:36,463] INFO Created log for partition __consumer_offsets-35 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,465] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-11-24 22:05:36,475] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,477] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,546] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,548] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:36,550] INFO Created log for partition __consumer_offsets-44 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,551] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-11-24 22:05:36,561] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,576] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,660] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,662] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-24 22:05:36,665] INFO Created log for partition __consumer_offsets-6 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,672] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-11-24 22:05:36,678] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,679] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,745] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,747] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:36,750] INFO Created log for partition __consumer_offsets-25 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,760] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-11-24 22:05:36,773] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,789] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:36,868] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:36,869] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:36,872] INFO Created log for partition __consumer_offsets-16 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:36,882] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-11-24 22:05:36,907] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:36,910] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,013] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,016] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:05:37,020] INFO Created log for partition __consumer_offsets-22 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,031] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-11-24 22:05:37,041] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,043] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,131] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,133] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:37,136] INFO Created log for partition __consumer_offsets-41 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,142] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-11-24 22:05:37,143] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,143] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,219] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,221] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:37,226] INFO Created log for partition __consumer_offsets-32 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,227] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-11-24 22:05:37,233] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,236] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,327] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,329] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:05:37,330] INFO Created log for partition __consumer_offsets-3 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,331] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-11-24 22:05:37,345] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,348] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,431] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,433] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:05:37,436] INFO Created log for partition __consumer_offsets-13 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,442] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-11-24 22:05:37,442] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,442] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:05:37,531] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:05:37,532] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:05:37,534] INFO Created log for partition testTopicName-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:05:37,547] INFO [Partition testTopicName-0 broker=0] No checkpointed highwatermark is found for partition testTopicName-0 (kafka.cluster.Partition)
[2019-11-24 22:05:37,551] INFO Replica loaded for partition testTopicName-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:05:37,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,579] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,580] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,586] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,590] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,605] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,629] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,637] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,638] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,649] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,653] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,673] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,676] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,687] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,694] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,697] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,706] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,711] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,713] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,743] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,751] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,752] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,777] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,780] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,780] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,781] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,789] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,790] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,811] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,814] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,815] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,824] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,830] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,842] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,850] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,850] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,875] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,879] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,880] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,887] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,895] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,896] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,904] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,906] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,914] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,914] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,922] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,935] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,939] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,941] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,956] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,965] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,965] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,986] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,991] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:37,998] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,005] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,022] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,026] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,028] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,036] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,038] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,060] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,071] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,073] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,075] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,076] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,079] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,093] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,098] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,099] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,107] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,109] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,110] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,130] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,133] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,134] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,142] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,147] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,149] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,161] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,168] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,174] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,176] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,191] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,192] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,216] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,226] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,242] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: testTopicName-0. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,245] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,250] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:05:38,251] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: testTopicName-0. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,269] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:05:38,271] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:05:38,286] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:05:38,289] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:05:38,351] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-13189 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-1-d60280c4-fc45-4a6b-9432-c945fe4a183b with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,361] INFO [GroupCoordinator 0]: Stabilized group console-consumer-13189 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,384] ERROR Error while renaming dir for testTopicName-0 in log dir D:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.d3d5483cebe74d218b9818090dd32677-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:784)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2085)
	at kafka.log.Log.renameDir(Log.scala:782)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:858)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:374)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:368)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:368)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:398)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:396)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:219)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:118)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.d3d5483cebe74d218b9818090dd32677-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 17 more
[2019-11-24 22:05:38,389] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-13189 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,391] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:05:38,423] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:05:38,426] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:05:38,459] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:05:38,460] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:05:38,461] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:05:38,468] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-13189 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: error when storing group assignment during SyncGroup (member: consumer-1-d60280c4-fc45-4a6b-9432-c945fe4a183b)) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:05:38,464] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:05:38,482] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:05:38,838] WARN Exception causing close of session 0x1001f52cdca0001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:05:38,839] INFO Closed socket connection for client /127.0.0.1:53058 which had sessionid 0x1001f52cdca0001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:05:46,012] INFO Expiring session 0x1001f52cdca0001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:05:46,012] INFO Processed session termination for sessionid: 0x1001f52cdca0001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:32,029] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:11:32,035] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:11:32,035] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:11:32,036] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:11:32,036] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:11:32,060] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:11:32,061] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:11:32,078] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,078] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,078] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,079] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,079] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,079] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,083] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,087] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,101] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,102] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,102] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,102] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,102] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,103] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,103] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,116] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,117] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,124] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:32,157] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:11:32,161] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:11:32,284] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:11:32,947] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:11:32,949] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:11:32,969] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:11:32,973] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,973] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,973] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,973] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,974] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,974] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,976] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,979] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,979] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,981] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,981] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,981] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,982] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,982] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,982] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:32,984] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:11:33,002] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:11:33,008] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:11:33,015] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:11:33,015] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53601 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:11:33,022] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53601 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:33,027] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:11:33,086] INFO Established session 0x1001f597c1c0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:53601 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:11:33,089] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f597c1c0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:11:33,100] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:11:33,204] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:33,334] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:33,440] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:33,932] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:34,026] INFO Cluster ID = NJwVfnfbTK6XKoNLlt6aIQ (kafka.server.KafkaServer)
[2019-11-24 22:11:34,030] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:11:34,080] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:11:34,095] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:11:34,119] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:11:34,119] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:11:34,124] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:11:34,150] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:11:34,162] INFO Logs loading complete in 11 ms. (kafka.log.LogManager)
[2019-11-24 22:11:34,176] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:11:34,179] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:11:34,461] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:11:34,495] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:11:34,497] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:11:34,518] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,519] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,520] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,520] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,537] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:11:34,560] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:11:34,608] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1574655094570,1574655094570,1,0,0,72092063232688128,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:11:34,609] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-11-24 22:11:34,610] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:11:34,702] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,704] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,705] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:11:34,746] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-11-24 22:11:34,752] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:11:34,754] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:11:34,759] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:34,813] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:11:34,839] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:11:34,841] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:11:34,842] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:11:34,882] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:11:34,895] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:11:34,902] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:11:34,902] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:11:34,903] INFO Kafka startTimeMs: 1574655094896 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:11:34,906] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:11:34,919] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:34,971] INFO Creating topic testTopicName with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-24 22:11:34,976] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:setData cxid:0x40 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/testTopicName Error:KeeperErrorCode = NoNode for /config/topics/testTopicName (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:35,078] INFO [KafkaApi-0] Auto creation of topic testTopicName with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-24 22:11:35,133] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-24 22:11:35,136] INFO Got user-level KeeperException when processing sessionid:0x1001f597c1c0000 type:setData cxid:0x4b zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:11:35,249] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:11:35,298] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-24 22:11:35,311] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:35,317] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 42 ms (kafka.log.Log)
[2019-11-24 22:11:35,319] INFO Created log for partition testTopicName-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:35,321] INFO [Partition testTopicName-0 broker=0] No checkpointed highwatermark is found for partition testTopicName-0 (kafka.cluster.Partition)
[2019-11-24 22:11:35,324] INFO Replica loaded for partition testTopicName-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:35,328] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:36,422] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:11:36,429] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:36,430] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:36,431] INFO Created log for partition __consumer_offsets-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:36,432] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-11-24 22:11:36,433] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:36,434] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:36,770] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:36,772] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:36,773] INFO Created log for partition __consumer_offsets-29 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:36,775] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-11-24 22:11:36,776] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:36,776] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:36,847] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:36,848] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:36,849] INFO Created log for partition __consumer_offsets-48 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:36,851] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-11-24 22:11:36,851] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:36,851] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:36,914] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:36,915] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:36,916] INFO Created log for partition __consumer_offsets-10 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:36,917] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-11-24 22:11:36,917] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:36,918] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:36,993] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:36,994] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:36,995] INFO Created log for partition __consumer_offsets-45 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:36,996] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-11-24 22:11:36,996] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:36,996] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,079] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,081] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-24 22:11:37,084] INFO Created log for partition __consumer_offsets-26 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,085] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-11-24 22:11:37,086] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,086] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,159] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,160] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:37,162] INFO Created log for partition __consumer_offsets-7 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,163] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-11-24 22:11:37,163] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,164] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,235] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,236] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,238] INFO Created log for partition __consumer_offsets-42 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,239] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-11-24 22:11:37,239] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,240] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,311] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,312] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,313] INFO Created log for partition __consumer_offsets-4 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,314] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-11-24 22:11:37,315] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,315] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,390] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,391] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,392] INFO Created log for partition __consumer_offsets-23 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,393] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-11-24 22:11:37,393] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,393] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,455] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,457] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:37,459] INFO Created log for partition __consumer_offsets-1 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,460] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,461] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,463] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,523] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,524] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:37,525] INFO Created log for partition __consumer_offsets-20 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,526] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-11-24 22:11:37,526] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,527] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,610] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,611] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,612] INFO Created log for partition __consumer_offsets-39 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,613] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-11-24 22:11:37,613] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,614] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,688] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,690] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:37,690] INFO Created log for partition __consumer_offsets-17 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,691] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-11-24 22:11:37,692] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,692] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,765] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,766] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,767] INFO Created log for partition __consumer_offsets-36 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,769] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-11-24 22:11:37,769] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,770] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,854] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,855] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:37,856] INFO Created log for partition __consumer_offsets-14 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,857] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-11-24 22:11:37,857] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,857] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:37,942] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:37,943] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:37,944] INFO Created log for partition __consumer_offsets-33 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:37,945] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-11-24 22:11:37,945] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:37,946] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,024] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,025] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:11:38,028] INFO Created log for partition __consumer_offsets-49 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,029] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-11-24 22:11:38,030] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,031] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,120] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,121] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:38,122] INFO Created log for partition __consumer_offsets-11 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,124] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-11-24 22:11:38,124] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,125] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,196] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,197] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,197] INFO Created log for partition __consumer_offsets-30 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,198] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-11-24 22:11:38,199] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,199] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,277] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,278] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:38,280] INFO Created log for partition __consumer_offsets-46 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,281] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-11-24 22:11:38,282] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,282] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,362] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,363] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,364] INFO Created log for partition __consumer_offsets-27 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,365] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-11-24 22:11:38,365] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,366] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,429] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,430] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,431] INFO Created log for partition __consumer_offsets-8 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,432] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-11-24 22:11:38,432] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,433] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,497] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,498] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,499] INFO Created log for partition __consumer_offsets-24 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,500] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-11-24 22:11:38,500] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,501] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,576] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,577] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:38,577] INFO Created log for partition __consumer_offsets-43 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,578] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-11-24 22:11:38,579] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,580] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,663] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,664] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,665] INFO Created log for partition __consumer_offsets-5 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,666] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-11-24 22:11:38,666] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,667] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,740] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,742] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:38,743] INFO Created log for partition __consumer_offsets-21 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,745] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-11-24 22:11:38,745] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,746] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,816] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,817] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:38,818] INFO Created log for partition __consumer_offsets-2 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,819] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-11-24 22:11:38,819] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,819] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,882] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,882] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:11:38,882] INFO Created log for partition __consumer_offsets-40 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,883] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-11-24 22:11:38,883] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,884] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:38,948] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:38,949] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:38,950] INFO Created log for partition __consumer_offsets-37 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:38,951] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-11-24 22:11:38,951] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:38,952] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,037] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,039] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:39,040] INFO Created log for partition __consumer_offsets-18 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,041] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-11-24 22:11:39,041] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,041] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,114] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,116] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:39,116] INFO Created log for partition __consumer_offsets-34 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,117] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-11-24 22:11:39,117] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,118] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,192] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,193] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:39,194] INFO Created log for partition __consumer_offsets-15 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,196] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-11-24 22:11:39,197] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,197] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,268] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,269] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:39,270] INFO Created log for partition __consumer_offsets-12 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,272] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-11-24 22:11:39,272] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,272] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,336] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,337] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:39,338] INFO Created log for partition __consumer_offsets-31 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,339] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-11-24 22:11:39,339] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,340] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,418] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,419] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:39,420] INFO Created log for partition __consumer_offsets-9 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,421] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-11-24 22:11:39,421] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,422] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,487] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,488] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:39,490] INFO Created log for partition __consumer_offsets-47 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,491] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-11-24 22:11:39,492] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,492] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,563] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,564] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:39,565] INFO Created log for partition __consumer_offsets-19 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,566] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-11-24 22:11:39,566] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,567] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,631] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,632] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:39,633] INFO Created log for partition __consumer_offsets-28 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,634] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-11-24 22:11:39,634] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,635] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,707] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,708] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:11:39,709] INFO Created log for partition __consumer_offsets-38 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,710] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-11-24 22:11:39,710] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,710] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,795] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,799] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:11:39,802] INFO Created log for partition __consumer_offsets-35 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,803] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-11-24 22:11:39,803] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,804] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,872] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,874] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:11:39,874] INFO Created log for partition __consumer_offsets-44 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,875] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-11-24 22:11:39,875] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,876] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:39,948] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:39,949] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:39,950] INFO Created log for partition __consumer_offsets-6 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:39,951] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-11-24 22:11:39,951] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:39,952] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,028] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,030] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:40,031] INFO Created log for partition __consumer_offsets-25 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,033] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-11-24 22:11:40,033] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,034] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,104] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,105] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:40,106] INFO Created log for partition __consumer_offsets-16 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,107] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-11-24 22:11:40,107] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,108] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,183] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,184] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:40,185] INFO Created log for partition __consumer_offsets-22 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,186] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-11-24 22:11:40,186] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,187] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,248] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,249] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:40,250] INFO Created log for partition __consumer_offsets-41 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,251] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-11-24 22:11:40,251] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,252] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,314] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,315] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:11:40,316] INFO Created log for partition __consumer_offsets-32 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,317] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-11-24 22:11:40,317] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,318] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,426] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,427] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:40,428] INFO Created log for partition __consumer_offsets-3 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,513] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-11-24 22:11:40,513] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,515] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,603] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:11:40,604] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:11:40,605] INFO Created log for partition __consumer_offsets-13 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:11:40,607] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-11-24 22:11:40,607] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:11:40,608] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:11:40,688] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,689] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,690] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,691] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,691] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,692] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,692] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,693] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,693] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,693] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,694] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,694] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,695] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,695] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,696] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,696] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,696] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,697] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,697] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,698] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,698] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,702] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,703] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,704] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,705] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,705] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 16 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,706] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,706] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,707] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,707] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,708] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,708] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,709] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,709] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,709] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,710] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,711] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,712] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,712] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,712] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,713] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,714] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,714] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,715] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,715] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,716] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,716] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,716] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,717] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,718] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,718] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,719] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,719] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,722] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,722] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,723] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,723] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,724] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,724] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,725] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,725] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,726] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,726] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,727] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,727] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,728] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,728] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,729] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,730] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,731] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,732] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,733] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,734] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,736] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,737] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,738] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,739] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,740] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,741] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,743] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,744] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,745] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,745] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,746] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,746] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,746] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,747] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,748] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,748] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,749] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:11:40,813] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-45854 in state PreparingRebalance with old generation 0 (__consumer_offsets-27) (reason: Adding new member consumer-1-f1d2c5f7-766d-4105-846b-dff12391dc40 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:11:40,820] INFO [GroupCoordinator 0]: Stabilized group console-consumer-45854 generation 1 (__consumer_offsets-27) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:11:40,828] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-45854 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:14:34,522] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: testTopicName-0. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:14:34,553] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:14:34,553] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:14:34,555] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:14:34,556] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:14:34,612] ERROR Error while renaming dir for testTopicName-0 in log dir D:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.44a12e20327f4fea9cb63d16f9265e59-delete
	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.Log.$anonfun$renameDir$2(Log.scala:784)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2085)
	at kafka.log.Log.renameDir(Log.scala:782)
	at kafka.log.LogManager.asyncDelete(LogManager.scala:858)
	at kafka.cluster.Partition.$anonfun$delete$1(Partition.scala:374)
	at kafka.utils.CoreUtils$.inLock(CoreUtils.scala:253)
	at kafka.utils.CoreUtils$.inWriteLock(CoreUtils.scala:261)
	at kafka.cluster.Partition.delete(Partition.scala:368)
	at kafka.server.ReplicaManager.stopReplica(ReplicaManager.scala:368)
	at kafka.server.ReplicaManager.$anonfun$stopReplicas$2(ReplicaManager.scala:398)
	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97)
	at kafka.server.ReplicaManager.stopReplicas(ReplicaManager.scala:396)
	at kafka.server.KafkaApis.handleStopReplicaRequest(KafkaApis.scala:219)
	at kafka.server.KafkaApis.handle(KafkaApis.scala:118)
	at kafka.server.KafkaRequestHandler.run(KafkaRequestHandler.scala:69)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.AccessDeniedException: D:\tmp\kafka-logs\testTopicName-0 -> D:\tmp\kafka-logs\testTopicName-0.44a12e20327f4fea9cb63d16f9265e59-delete
		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:89)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 17 more
[2019-11-24 22:14:34,616] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:14:34,620] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:14:34,621] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:14:34,639] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:14:34,640] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:14:34,645] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:14:34,984] WARN Exception causing close of session 0x1001f597c1c0000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:14:34,986] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53601 which had sessionid 0x1001f597c1c0000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:14:43,013] INFO Expiring session 0x1001f597c1c0000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:14:43,013] INFO Processed session termination for sessionid: 0x1001f597c1c0000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:08,507] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:16:08,512] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:16:08,512] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:16:08,512] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:16:08,513] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:16:08,534] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:16:08,535] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:16:08,551] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,551] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,552] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,552] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,552] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,552] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,556] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,565] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,565] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,566] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,566] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,567] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,567] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,567] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,567] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,586] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,586] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,587] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:08,624] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:16:08,630] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:16:08,788] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:16:09,467] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:16:09,468] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:16:09,486] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:16:09,491] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,491] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,491] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,491] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,491] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,492] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,494] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,498] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,498] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,499] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,499] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,500] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,501] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,501] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,501] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,503] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:16:09,519] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:16:09,525] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:16:09,529] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:16:09,529] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53752 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:16:09,539] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53752 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:09,542] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:16:09,579] INFO Established session 0x1001f5db4120000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:53752 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:16:09,580] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f5db4120000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:16:09,583] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:16:09,654] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:09,801] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:09,906] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:10,667] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:10,766] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:16:10,769] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:16:10,816] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:16:10,829] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:16:10,854] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:16:10,855] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:16:10,857] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:16:10,877] INFO Log directory D:\tmp\kafka-logs not found, creating it. (kafka.log.LogManager)
[2019-11-24 22:16:10,883] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:16:10,893] INFO Logs loading complete in 9 ms. (kafka.log.LogManager)
[2019-11-24 22:16:10,907] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:16:10,910] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:16:11,181] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:16:11,208] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:16:11,210] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:16:11,235] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,236] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,237] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,237] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,250] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:16:11,271] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:16:11,314] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1574655371284,1574655371284,1,0,0,72092081351426048,200,0,24
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:16:11,316] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2019-11-24 22:16:11,317] WARN No meta.properties file under dir D:\tmp\kafka-logs\meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-11-24 22:16:11,448] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,451] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,451] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:16:11,493] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2019-11-24 22:16:11,502] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:11,503] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:11,506] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:11,561] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:16:11,586] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:16:11,590] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:16:11,591] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:16:11,626] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:16:11,636] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:16:11,646] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:16:11,646] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:16:11,647] INFO Kafka startTimeMs: 1574655371638 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:16:11,651] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:16:11,671] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:multi cxid:0x38 zxid:0x1c txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:11,726] INFO Creating topic testTopicName with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-24 22:16:11,729] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:setData cxid:0x40 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics/testTopicName Error:KeeperErrorCode = NoNode for /config/topics/testTopicName (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:11,851] INFO [KafkaApi-0] Auto creation of topic testTopicName with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-24 22:16:11,952] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2019-11-24 22:16:11,954] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120000 type:setData cxid:0x4c zxid:0x23 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:16:11,992] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(testTopicName-0) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:16:12,060] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:12,067] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 37 ms (kafka.log.Log)
[2019-11-24 22:16:12,069] INFO Created log for partition testTopicName-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 1073741824, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:12,070] INFO [Partition testTopicName-0 broker=0] No checkpointed highwatermark is found for partition testTopicName-0 (kafka.cluster.Partition)
[2019-11-24 22:16:12,072] INFO Replica loaded for partition testTopicName-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:12,074] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:12,077] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2019-11-24 22:16:13,173] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:16:13,180] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,182] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:16:13,183] INFO Created log for partition __consumer_offsets-0 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,184] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2019-11-24 22:16:13,185] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,186] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,253] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,254] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:13,255] INFO Created log for partition __consumer_offsets-29 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,256] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2019-11-24 22:16:13,256] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,257] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,332] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,333] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,334] INFO Created log for partition __consumer_offsets-48 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,336] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2019-11-24 22:16:13,336] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,336] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,407] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,408] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:13,409] INFO Created log for partition __consumer_offsets-10 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,410] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2019-11-24 22:16:13,410] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,411] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,485] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,487] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,488] INFO Created log for partition __consumer_offsets-45 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,488] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2019-11-24 22:16:13,489] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,489] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,552] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,553] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,554] INFO Created log for partition __consumer_offsets-26 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,555] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2019-11-24 22:16:13,555] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,556] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,618] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,619] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,620] INFO Created log for partition __consumer_offsets-7 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,621] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2019-11-24 22:16:13,621] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,621] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,684] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,686] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,687] INFO Created log for partition __consumer_offsets-42 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,688] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2019-11-24 22:16:13,688] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,689] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,762] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,763] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:13,764] INFO Created log for partition __consumer_offsets-4 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,765] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2019-11-24 22:16:13,765] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,766] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,850] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,851] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:16:13,852] INFO Created log for partition __consumer_offsets-23 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,853] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2019-11-24 22:16:13,854] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,855] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,930] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:13,932] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:13,933] INFO Created log for partition __consumer_offsets-1 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:13,934] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2019-11-24 22:16:13,934] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:13,935] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,023] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,025] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:16:14,026] INFO Created log for partition __consumer_offsets-20 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,028] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2019-11-24 22:16:14,029] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,029] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,108] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,109] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:14,111] INFO Created log for partition __consumer_offsets-39 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,112] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2019-11-24 22:16:14,113] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,114] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,194] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,196] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:16:14,197] INFO Created log for partition __consumer_offsets-17 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,199] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2019-11-24 22:16:14,200] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,201] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,299] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,301] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 10 ms (kafka.log.Log)
[2019-11-24 22:16:14,302] INFO Created log for partition __consumer_offsets-36 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,303] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2019-11-24 22:16:14,304] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,304] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,383] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,384] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:14,385] INFO Created log for partition __consumer_offsets-14 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,387] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2019-11-24 22:16:14,388] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,388] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,462] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,464] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:16:14,465] INFO Created log for partition __consumer_offsets-33 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,466] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2019-11-24 22:16:14,466] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,467] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,547] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,548] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:14,549] INFO Created log for partition __consumer_offsets-49 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,550] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2019-11-24 22:16:14,551] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,551] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,624] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,625] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:14,626] INFO Created log for partition __consumer_offsets-11 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,627] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2019-11-24 22:16:14,628] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,628] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,704] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,705] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:14,706] INFO Created log for partition __consumer_offsets-30 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,707] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2019-11-24 22:16:14,708] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,708] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,780] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,782] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:14,783] INFO Created log for partition __consumer_offsets-46 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,784] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2019-11-24 22:16:14,784] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,785] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,867] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,868] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:14,869] INFO Created log for partition __consumer_offsets-27 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,870] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2019-11-24 22:16:14,870] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,871] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:14,938] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:14,941] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:16:14,941] INFO Created log for partition __consumer_offsets-8 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:14,942] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2019-11-24 22:16:14,943] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:14,943] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,009] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,011] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,013] INFO Created log for partition __consumer_offsets-24 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,016] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2019-11-24 22:16:15,017] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,021] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,101] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,102] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,103] INFO Created log for partition __consumer_offsets-43 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,104] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2019-11-24 22:16:15,104] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,104] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,177] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,178] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,178] INFO Created log for partition __consumer_offsets-5 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,180] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2019-11-24 22:16:15,181] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,181] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,254] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,255] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,256] INFO Created log for partition __consumer_offsets-21 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,257] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2019-11-24 22:16:15,257] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,258] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,342] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,343] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,345] INFO Created log for partition __consumer_offsets-2 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,346] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2019-11-24 22:16:15,347] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,347] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,420] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,421] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,422] INFO Created log for partition __consumer_offsets-40 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,423] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2019-11-24 22:16:15,425] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,425] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,498] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,500] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:15,502] INFO Created log for partition __consumer_offsets-37 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,503] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2019-11-24 22:16:15,504] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,504] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,574] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,575] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,576] INFO Created log for partition __consumer_offsets-18 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,577] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2019-11-24 22:16:15,578] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,579] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,641] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,642] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,643] INFO Created log for partition __consumer_offsets-34 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,644] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2019-11-24 22:16:15,644] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,645] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,707] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,708] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:16:15,709] INFO Created log for partition __consumer_offsets-15 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,710] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2019-11-24 22:16:15,710] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,710] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,797] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,798] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:15,799] INFO Created log for partition __consumer_offsets-12 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,800] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2019-11-24 22:16:15,801] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,801] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,873] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,874] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,875] INFO Created log for partition __consumer_offsets-31 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,875] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2019-11-24 22:16:15,876] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,876] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:15,957] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:15,958] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:15,959] INFO Created log for partition __consumer_offsets-9 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:15,960] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2019-11-24 22:16:15,960] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:15,961] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,033] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,034] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,035] INFO Created log for partition __consumer_offsets-47 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,036] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2019-11-24 22:16:16,036] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,037] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,102] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,104] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:16:16,104] INFO Created log for partition __consumer_offsets-19 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,106] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2019-11-24 22:16:16,106] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,107] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,178] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,179] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,180] INFO Created log for partition __consumer_offsets-28 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,181] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2019-11-24 22:16:16,181] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,182] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,254] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,255] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,256] INFO Created log for partition __consumer_offsets-38 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,257] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2019-11-24 22:16:16,257] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,257] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,332] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,333] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:16:16,334] INFO Created log for partition __consumer_offsets-35 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,335] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2019-11-24 22:16:16,335] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,336] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,409] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,410] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,411] INFO Created log for partition __consumer_offsets-44 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,413] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2019-11-24 22:16:16,413] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,414] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,487] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,488] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,488] INFO Created log for partition __consumer_offsets-6 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,489] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2019-11-24 22:16:16,489] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,490] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,553] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,554] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,555] INFO Created log for partition __consumer_offsets-25 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,556] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2019-11-24 22:16:16,556] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,556] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,619] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,621] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:16,621] INFO Created log for partition __consumer_offsets-16 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,622] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2019-11-24 22:16:16,623] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,623] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,708] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,709] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:16:16,709] INFO Created log for partition __consumer_offsets-22 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,710] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2019-11-24 22:16:16,710] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,711] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,808] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,810] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-24 22:16:16,812] INFO Created log for partition __consumer_offsets-41 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,814] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2019-11-24 22:16:16,814] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,816] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,898] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,902] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:16:16,903] INFO Created log for partition __consumer_offsets-32 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:16,906] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2019-11-24 22:16:16,909] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:16,910] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:16,997] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:16,998] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:16:16,999] INFO Created log for partition __consumer_offsets-3 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:17,000] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2019-11-24 22:16:17,001] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:17,001] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:17,073] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:16:17,073] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:16:17,074] INFO Created log for partition __consumer_offsets-13 in D:\tmp\kafka-logs with properties {compression.type -> producer, min.insync.replicas -> 1, message.downconversion.enable -> true, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, retention.ms -> 604800000, segment.bytes -> 104857600, flush.messages -> 9223372036854775807, message.format.version -> 2.3-IV1, max.compaction.lag.ms -> 9223372036854775807, file.delete.delay.ms -> 60000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, index.interval.bytes -> 4096, min.cleanable.dirty.ratio -> 0.5, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2019-11-24 22:16:17,075] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2019-11-24 22:16:17,075] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:16:17,076] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:16:17,156] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,158] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,162] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,163] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,165] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,165] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,166] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,167] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,168] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,169] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,170] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,174] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,175] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,176] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,177] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,178] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,178] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,179] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,180] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,180] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 22 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,180] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,181] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,182] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,183] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,184] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,184] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,185] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,185] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,185] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,186] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,186] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,187] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,187] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,187] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,188] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,188] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,189] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,189] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,189] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,190] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,190] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,190] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,191] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,191] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,191] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,192] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,194] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,194] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,195] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,195] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,196] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,196] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,196] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,197] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,197] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,198] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,198] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,199] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,199] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,200] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,200] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,200] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,201] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,201] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,201] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,202] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,204] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,204] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,205] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,205] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,206] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,206] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,207] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,207] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,208] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,208] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,209] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,210] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,211] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,211] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,212] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,213] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,215] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,215] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,216] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,216] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,218] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,219] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,220] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:16:17,258] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-32367 in state PreparingRebalance with old generation 0 (__consumer_offsets-12) (reason: Adding new member consumer-1-a71f043d-f7d5-4f4c-b250-b0d42649ad97 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:17,269] INFO [GroupCoordinator 0]: Stabilized group console-consumer-32367 generation 1 (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:17,276] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-32367 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:45,323] INFO [GroupCoordinator 0]: Member consumer-1-a71f043d-f7d5-4f4c-b250-b0d42649ad97 in group console-consumer-32367 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:45,324] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-32367 in state PreparingRebalance with old generation 1 (__consumer_offsets-12) (reason: removing member consumer-1-a71f043d-f7d5-4f4c-b250-b0d42649ad97 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:45,325] INFO [GroupCoordinator 0]: Group console-consumer-32367 with generation 2 is now empty (__consumer_offsets-12) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:50,723] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90269 in state PreparingRebalance with old generation 0 (__consumer_offsets-47) (reason: Adding new member consumer-1-2347d524-1c01-49b8-b535-9cac7ad8245f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:50,724] INFO [GroupCoordinator 0]: Stabilized group console-consumer-90269 generation 1 (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:16:50,727] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-90269 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:09,735] INFO [GroupCoordinator 0]: Member consumer-1-2347d524-1c01-49b8-b535-9cac7ad8245f in group console-consumer-90269 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:09,736] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-90269 in state PreparingRebalance with old generation 1 (__consumer_offsets-47) (reason: removing member consumer-1-2347d524-1c01-49b8-b535-9cac7ad8245f on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:09,739] INFO [GroupCoordinator 0]: Group console-consumer-90269 with generation 2 is now empty (__consumer_offsets-47) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:46,962] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-63120 in state PreparingRebalance with old generation 0 (__consumer_offsets-13) (reason: Adding new member consumer-1-579c3284-4206-470e-ada9-1f2fa5f411ec with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:46,963] INFO [GroupCoordinator 0]: Stabilized group console-consumer-63120 generation 1 (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:46,966] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-63120 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:56,639] INFO [GroupCoordinator 0]: Member consumer-1-579c3284-4206-470e-ada9-1f2fa5f411ec in group console-consumer-63120 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:56,639] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-63120 in state PreparingRebalance with old generation 1 (__consumer_offsets-13) (reason: removing member consumer-1-579c3284-4206-470e-ada9-1f2fa5f411ec on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:17:56,640] INFO [GroupCoordinator 0]: Group console-consumer-63120 with generation 2 is now empty (__consumer_offsets-13) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:18:22,102] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53792 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:18:22,105] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53792 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:18:22,137] INFO Established session 0x1001f5db4120001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53792 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:18:22,177] INFO Processed session termination for sessionid: 0x1001f5db4120001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:18:22,203] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53792 which had sessionid 0x1001f5db4120001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:18:57,112] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53800 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:18:57,115] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53800 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:18:57,234] INFO Established session 0x1001f5db4120002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53800 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:18:57,454] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120002 type:create cxid:0x5 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:18:57,533] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:18:57,534] INFO Processed session termination for sessionid: 0x1001f5db4120002 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:18:57,570] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53800 which had sessionid 0x1001f5db4120002 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:18:57,571] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-11-24 22:19:28,257] INFO Accepted socket connection from /127.0.0.1:53805 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:19:28,261] INFO Client attempting to establish new session at /127.0.0.1:53805 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:19:28,291] INFO Established session 0x1001f5db4120003 with negotiated timeout 30000 for client /127.0.0.1:53805 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:19:28,804] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120003 type:create cxid:0x5 zxid:0x94 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:19:28,879] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:19:28,881] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:19:28,881] INFO Processed session termination for sessionid: 0x1001f5db4120003 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:19:28,917] INFO Closed socket connection for client /127.0.0.1:53805 which had sessionid 0x1001f5db4120003 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:21:27,263] INFO Accepted socket connection from /127.0.0.1:53813 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:21:27,266] INFO Client attempting to establish new session at /127.0.0.1:53813 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:21:27,290] INFO Established session 0x1001f5db4120004 with negotiated timeout 30000 for client /127.0.0.1:53813 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:21:27,507] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120004 type:create cxid:0x4 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:21:27,570] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:21:27,572] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 1000) (kafka.server.DynamicConfigManager)
[2019-11-24 22:21:27,574] INFO Processed session termination for sessionid: 0x1001f5db4120004 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:21:27,933] INFO Closed socket connection for client /127.0.0.1:53813 which had sessionid 0x1001f5db4120004 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:21:36,486] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:53818 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:21:36,489] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:53818 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:21:36,609] INFO Established session 0x1001f5db4120005 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:53818 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:21:36,818] INFO Got user-level KeeperException when processing sessionid:0x1001f5db4120005 type:create cxid:0x4 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:21:36,881] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:21:36,886] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:21:36,899] INFO Processed session termination for sessionid: 0x1001f5db4120005 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:21:36,940] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53818 which had sessionid 0x1001f5db4120005 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:21:49,779] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-44110 in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member consumer-1-fe93f076-f7ad-4149-9a27-7021915cd4a4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:21:49,780] INFO [GroupCoordinator 0]: Stabilized group console-consumer-44110 generation 1 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:21:49,783] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-44110 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:26:11,507] INFO [GroupMetadataManager brokerId=0] Group console-consumer-63120 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:26:11,508] INFO [GroupMetadataManager brokerId=0] Group console-consumer-32367 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:26:11,509] INFO [GroupMetadataManager brokerId=0] Group console-consumer-90269 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:26:11,509] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:26:40,911] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Found deletable segments with base offsets [0] due to retention time 604800ms breach (kafka.log.Log)
[2019-11-24 22:26:40,926] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:26:40,932] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Rolled new log segment at offset 9 in 20 ms. (kafka.log.Log)
[2019-11-24 22:26:40,933] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Scheduling log segment [baseOffset 0, size 261] for deletion. (kafka.log.Log)
[2019-11-24 22:26:40,939] ERROR Error while deleting segments for testTopicName-0 in dir D:\tmp\kafka-logs (kafka.server.LogDirFailureChannel)
java.nio.file.FileSystemException: D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex -> D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.asyncDeleteSegment(Log.scala:1982)
	at kafka.log.Log.deleteSegment(Log.scala:1967)
	at kafka.log.Log.$anonfun$deleteSegments$3(Log.scala:1493)
	at kafka.log.Log.$anonfun$deleteSegments$3$adapted(Log.scala:1493)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.Log.$anonfun$deleteSegments$2(Log.scala:1493)
	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2085)
	at kafka.log.Log.deleteSegments(Log.scala:1484)
	at kafka.log.Log.deleteOldSegments(Log.scala:1479)
	at kafka.log.Log.deleteRetentionMsBreachedSegments(Log.scala:1557)
	at kafka.log.Log.deleteOldSegments(Log.scala:1547)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:914)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:911)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:911)
	at kafka.log.LogManager.$anonfun$startup$2(LogManager.scala:395)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex -> D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 29 more
[2019-11-24 22:26:40,950] INFO [ReplicaManager broker=0] Stopping serving replicas in dir D:\tmp\kafka-logs (kafka.server.ReplicaManager)
[2019-11-24 22:26:40,951] ERROR Uncaught exception in scheduled task 'kafka-log-retention' (kafka.utils.KafkaScheduler)
org.apache.kafka.common.errors.KafkaStorageException: Error while deleting segments for testTopicName-0 in dir D:\tmp\kafka-logs
Caused by: java.nio.file.FileSystemException: D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex -> D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process.

	at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
	at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
	at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:395)
	at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
	at java.base/java.nio.file.Files.move(Files.java:1421)
	at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:815)
	at kafka.log.AbstractIndex.renameTo(AbstractIndex.scala:209)
	at kafka.log.LogSegment.changeFileSuffixes(LogSegment.scala:510)
	at kafka.log.Log.asyncDeleteSegment(Log.scala:1982)
	at kafka.log.Log.deleteSegment(Log.scala:1967)
	at kafka.log.Log.$anonfun$deleteSegments$3(Log.scala:1493)
	at kafka.log.Log.$anonfun$deleteSegments$3$adapted(Log.scala:1493)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at kafka.log.Log.$anonfun$deleteSegments$2(Log.scala:1493)
	at scala.runtime.java8.JFunction0$mcI$sp.apply(JFunction0$mcI$sp.java:23)
	at kafka.log.Log.maybeHandleIOException(Log.scala:2085)
	at kafka.log.Log.deleteSegments(Log.scala:1484)
	at kafka.log.Log.deleteOldSegments(Log.scala:1479)
	at kafka.log.Log.deleteRetentionMsBreachedSegments(Log.scala:1557)
	at kafka.log.Log.deleteOldSegments(Log.scala:1547)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3(LogManager.scala:914)
	at kafka.log.LogManager.$anonfun$cleanupLogs$3$adapted(LogManager.scala:911)
	at scala.collection.immutable.List.foreach(List.scala:392)
	at kafka.log.LogManager.cleanupLogs(LogManager.scala:911)
	at kafka.log.LogManager.$anonfun$startup$2(LogManager.scala:395)
	at kafka.utils.KafkaScheduler.$anonfun$schedule$2(KafkaScheduler.scala:114)
	at kafka.utils.CoreUtils$$anon$1.run(CoreUtils.scala:65)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
	Suppressed: java.nio.file.FileSystemException: D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex -> D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex.deleted: The process cannot access the file because it is being used by another process.

		at java.base/sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92)
		at java.base/sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103)
		at java.base/sun.nio.fs.WindowsFileCopy.move(WindowsFileCopy.java:309)
		at java.base/sun.nio.fs.WindowsFileSystemProvider.move(WindowsFileSystemProvider.java:288)
		at java.base/java.nio.file.Files.move(Files.java:1421)
		at org.apache.kafka.common.utils.Utils.atomicMoveWithFallback(Utils.java:812)
		... 29 more
[2019-11-24 22:26:40,953] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:26:40,956] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:26:40,973] INFO [ReplicaManager broker=0] Broker 0 stopped fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,__consumer_offsets-25,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,__consumer_offsets-47,__consumer_offsets-16,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,testTopicName-0,__consumer_offsets-37,__consumer_offsets-15,__consumer_offsets-24,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,__consumer_offsets-13,__consumer_offsets-2,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,__consumer_offsets-29,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 and stopped moving logs for partitions  because they are in the failed log directory D:\tmp\kafka-logs. (kafka.server.ReplicaManager)
[2019-11-24 22:26:40,975] INFO Stopping serving logs in dir D:\tmp\kafka-logs (kafka.log.LogManager)
[2019-11-24 22:26:40,978] ERROR Shutdown broker because all log dirs in D:\tmp\kafka-logs have failed (kafka.log.LogManager)
[2019-11-24 22:26:41,327] WARN Exception causing close of session 0x1001f5db4120000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:26:41,328] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:53752 which had sessionid 0x1001f5db4120000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:26:49,012] INFO Expiring session 0x1001f5db4120000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:26:49,012] INFO Processed session termination for sessionid: 0x1001f5db4120000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:07,378] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:31:07,382] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:31:07,382] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:31:07,382] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:31:07,382] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:31:07,404] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:31:07,405] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:31:07,422] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,423] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,424] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,424] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,424] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,425] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,431] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,441] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,447] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,448] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,448] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,448] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,448] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,449] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,449] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,470] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,470] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,471] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:07,507] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:31:07,513] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:31:07,666] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:31:08,331] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:31:08,333] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:31:08,353] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:31:08,357] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,357] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,358] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,358] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,358] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,358] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,361] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,365] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,371] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,371] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,371] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,372] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,372] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,372] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,372] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,374] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:31:08,393] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:31:08,399] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:31:08,403] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:31:08,403] INFO Accepted socket connection from /127.0.0.1:54492 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:31:08,410] INFO Client attempting to establish new session at /127.0.0.1:54492 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:08,412] INFO Creating new log file: log.a2 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:31:08,554] INFO Established session 0x1001f6b6b760000 with negotiated timeout 6000 for client /127.0.0.1:54492 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:31:08,559] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f6b6b760000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:31:08,573] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:31:08,619] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x1 zxid:0xa3 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,664] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x2 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,706] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x3 zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,740] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x4 zxid:0xa6 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,774] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x5 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,817] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x6 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,845] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x7 zxid:0xa9 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,873] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x8 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,900] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0x9 zxid:0xab txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,930] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0xa zxid:0xac txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,966] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0xb zxid:0xad txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:08,997] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0xc zxid:0xae txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:09,033] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:create cxid:0xd zxid:0xaf txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:09,168] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:31:09,220] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:31:09,235] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:31:09,268] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:31:09,269] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:31:09,287] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:31:09,313] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:31:09,374] WARN [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Found an orphaned index file D:\tmp\kafka-logs\testTopicName-0\00000000000000000000.timeindex, with no corresponding log file. (kafka.log.Log)
[2019-11-24 22:31:09,385] ERROR [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Could not find offset index file corresponding to log file D:\tmp\kafka-logs\testTopicName-0\00000000000000000009.log, recovering segment and rebuilding index files... (kafka.log.Log)
[2019-11-24 22:31:09,385] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,402] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:09,460] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:31:09,462] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,463] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000000009.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:09,553] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,557] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 9 and log end offset 9 in 203 ms (kafka.log.Log)
[2019-11-24 22:31:09,581] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,609] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,667] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,669] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 92 ms (kafka.log.Log)
[2019-11-24 22:31:09,673] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,673] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,728] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,729] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:31:09,733] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,734] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,788] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,789] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:31:09,797] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,798] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,848] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,850] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 55 ms (kafka.log.Log)
[2019-11-24 22:31:09,853] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,854] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,868] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:31:09,923] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,931] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:09,935] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 83 ms (kafka.log.Log)
[2019-11-24 22:31:09,951] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:09,952] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:09,971] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:31:10,075] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,076] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:10,077] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 134 ms (kafka.log.Log)
[2019-11-24 22:31:10,082] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,082] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,149] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,153] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-11-24 22:31:10,161] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,162] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,218] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,219] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:31:10,225] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,225] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,278] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,280] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:31:10,284] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,284] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,350] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,351] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:31:10,355] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,355] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,422] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,424] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 22:31:10,428] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,428] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,497] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,500] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-11-24 22:31:10,510] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,510] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,588] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,589] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 83 ms (kafka.log.Log)
[2019-11-24 22:31:10,592] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,592] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,659] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,661] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 22:31:10,664] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,664] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,730] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,731] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:31:10,735] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,735] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,805] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:10,809] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 76 ms (kafka.log.Log)
[2019-11-24 22:31:10,816] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:10,817] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,039] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,042] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 229 ms (kafka.log.Log)
[2019-11-24 22:31:11,046] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,046] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,567] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,568] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 524 ms (kafka.log.Log)
[2019-11-24 22:31:11,571] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,572] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,673] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,676] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 107 ms (kafka.log.Log)
[2019-11-24 22:31:11,681] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,681] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,744] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,745] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-11-24 22:31:11,749] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,750] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,804] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,805] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:31:11,810] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,810] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,866] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,868] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:31:11,872] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,872] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,937] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:11,941] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 22:31:11,946] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:11,947] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,008] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,009] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-24 22:31:12,012] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,013] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,069] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,070] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:31:12,073] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,074] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,083] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:31:12,130] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,131] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:12,132] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 61 ms (kafka.log.Log)
[2019-11-24 22:31:12,135] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,135] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,191] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,194] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:31:12,198] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,198] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,252] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,253] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:31:12,258] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,258] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,323] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,324] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:31:12,327] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,327] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,386] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,393] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:31:12,404] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,405] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,466] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,467] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-11-24 22:31:12,470] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,471] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,527] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,529] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:31:12,531] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,532] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,599] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,600] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:31:12,602] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,603] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,661] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,662] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:31:12,665] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,665] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,737] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,738] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-11-24 22:31:12,742] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,742] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,797] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,798] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:31:12,801] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,801] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,870] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,871] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-11-24 22:31:12,875] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,875] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,930] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,931] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:31:12,934] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,934] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,991] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:12,992] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:31:12,996] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:12,996] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,051] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,052] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:31:13,056] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,058] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,134] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,135] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 22:31:13,139] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,140] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,184] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,185] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 49 ms (kafka.log.Log)
[2019-11-24 22:31:13,189] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,189] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,200] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:31:13,266] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,267] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:31:13,267] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 81 ms (kafka.log.Log)
[2019-11-24 22:31:13,270] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,270] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,328] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,330] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-11-24 22:31:13,333] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,334] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,387] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,389] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:31:13,391] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,392] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,460] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,462] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-11-24 22:31:13,466] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,466] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,618] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,619] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 155 ms (kafka.log.Log)
[2019-11-24 22:31:13,622] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,622] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,680] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,682] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 62 ms (kafka.log.Log)
[2019-11-24 22:31:13,686] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,686] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,751] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,752] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:31:13,756] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:31:13,756] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,823] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:31:13,824] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:31:13,827] INFO Logs loading complete in 4514 ms. (kafka.log.LogManager)
[2019-11-24 22:31:13,836] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:31:13,837] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:31:14,062] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:31:14,092] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:31:14,095] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:31:14,126] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,129] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,129] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,132] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,145] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:31:14,200] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:31:14,264] INFO Stat of the created znode at /brokers/ids/0 is: 176,176,1574656274229,1574656274229,1,0,0,72092140262785024,200,0,176
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:31:14,264] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 176 (kafka.zk.KafkaZkClient)
[2019-11-24 22:31:14,306] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,309] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,309] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:31:14,366] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:14,368] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:14,373] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:14,414] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:1000,blockEndProducerId:1999) by writing to Zk with path version 2 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:31:14,445] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:31:14,446] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:31:14,447] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:31:14,483] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:31:14,485] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:31:14,493] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:31:14,500] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:31:14,503] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:31:14,503] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:31:14,511] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:31:14,516] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:31:14,516] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:31:14,517] INFO Kafka startTimeMs: 1574656274507 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:31:14,519] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:31:14,577] INFO Got user-level KeeperException when processing sessionid:0x1001f6b6b760000 type:multi cxid:0x75 zxid:0xb3 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:31:14,605] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:31:14,624] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,629] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,686] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,686] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,732] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,733] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,805] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,807] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,866] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,870] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,923] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,924] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:14,987] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:14,988] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,032] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,033] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,093] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,094] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,153] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,154] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,215] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,216] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,264] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,264] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,313] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,313] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,364] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,365] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,431] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,431] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,491] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,491] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,551] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,551] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,611] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,611] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,669] INFO Replica loaded for partition testTopicName-0 with initial high watermark 9 (kafka.cluster.Replica)
[2019-11-24 22:31:15,670] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 9. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,687] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,702] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,765] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,765] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,815] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,816] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,865] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,865] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,905] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,906] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:15,955] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:15,955] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,015] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,016] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,076] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,076] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,136] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,136] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,197] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,198] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,246] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,247] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,299] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,300] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,346] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,347] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,384] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,385] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,449] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,449] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,505] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:31:16,506] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,509] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 1 (kafka.cluster.Replica)
[2019-11-24 22:31:16,509] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,512] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,512] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,567] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:31:16,568] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,572] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,572] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,627] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,627] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,678] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,679] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,726] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,727] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,793] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,794] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,852] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,853] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,903] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,903] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:16,952] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:16,953] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,012] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:17,015] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,064] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:17,064] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,102] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:17,103] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,170] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:31:17,172] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,537] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:31:17,538] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:31:17,546] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,546] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,547] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,548] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,549] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,549] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,550] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,551] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,552] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,553] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,554] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,554] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,554] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,555] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,557] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,558] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,558] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,558] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 11 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,559] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,560] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,560] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,561] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,562] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,563] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,563] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,565] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,568] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,568] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,571] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,572] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,573] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,574] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,574] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,578] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,591] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-44110 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:17,599] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 37 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,600] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,601] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,601] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,602] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,602] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,603] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,607] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,608] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,616] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,617] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,618] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,618] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,618] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,619] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,619] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,620] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,621] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,627] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,628] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,632] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,633] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,634] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,634] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,635] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,635] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,637] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,638] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,639] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,639] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,640] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,641] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:31:17,646] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-11308 in state PreparingRebalance with old generation 0 (__consumer_offsets-44) (reason: Adding new member consumer-1-37316ab1-f9cc-4633-8bb0-27abaa0ffa62 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:17,651] INFO [GroupCoordinator 0]: Stabilized group console-consumer-11308 generation 1 (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:17,662] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-11308 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:27,603] INFO [GroupCoordinator 0]: Member consumer-1-fe93f076-f7ad-4149-9a27-7021915cd4a4 in group console-consumer-44110 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:27,604] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-44110 in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member consumer-1-fe93f076-f7ad-4149-9a27-7021915cd4a4 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:31:27,605] INFO [GroupCoordinator 0]: Group console-consumer-44110 with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:02,090] WARN Exception causing close of session 0x1001f6b6b760000: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:37:02,091] INFO Closed socket connection for client /127.0.0.1:54492 which had sessionid 0x1001f6b6b760000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:37:14,754] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:37:14,758] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:37:14,759] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:37:14,760] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:37:14,760] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:37:14,776] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:37:14,776] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:37:14,785] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,786] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,786] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,786] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,787] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,787] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,792] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,795] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,802] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,802] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,802] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,803] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,803] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,803] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,803] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,816] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,816] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,817] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:14,837] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:37:14,839] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:37:14,886] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:37:15,381] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:37:15,382] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:37:15,400] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:15,404] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,404] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,404] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,404] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,404] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,404] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,407] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,410] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,415] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,415] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,415] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,415] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,416] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,416] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,416] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,417] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:15,438] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:15,441] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:15,444] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:15,449] INFO Accepted socket connection from /127.0.0.1:54590 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:37:15,452] INFO Client attempting to establish new session at /127.0.0.1:54590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:15,453] INFO Creating new log file: log.b4 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:37:15,486] INFO Established session 0x1001f7106410000 with negotiated timeout 6000 for client /127.0.0.1:54590 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:15,493] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f7106410000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:15,506] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:15,564] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x1 zxid:0xb5 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,612] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x2 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,645] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x3 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,682] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x4 zxid:0xb8 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,717] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x5 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,762] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x6 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,798] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x7 zxid:0xbb txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,837] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x8 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,864] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0x9 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,903] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0xa zxid:0xbe txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,930] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0xb zxid:0xbf txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,959] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0xc zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:15,997] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:create cxid:0xd zxid:0xc1 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:16,131] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:37:16,201] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:37:16,214] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:37:16,254] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:16,254] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:16,280] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:16,320] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:37:16,385] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:37:16,387] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,398] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:16,499] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 2610 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:16,571] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2610 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,574] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000002610.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:16,582] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 9 and log end offset 2610 in 226 ms (kafka.log.Log)
[2019-11-24 22:37:16,599] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:16,600] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,674] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,677] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 22:37:16,686] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:16,697] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,763] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,765] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 82 ms (kafka.log.Log)
[2019-11-24 22:37:16,771] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:16,776] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,846] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,847] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-11-24 22:37:16,864] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:16,865] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,940] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,941] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 22:37:16,946] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:16,950] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:16,961] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:17,023] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,026] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:17,029] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 85 ms (kafka.log.Log)
[2019-11-24 22:37:17,051] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,051] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,070] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:17,131] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,133] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:17,135] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 86 ms (kafka.log.Log)
[2019-11-24 22:37:17,162] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,162] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,231] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,233] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 73 ms (kafka.log.Log)
[2019-11-24 22:37:17,237] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,242] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,315] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,316] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 22:37:17,321] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,325] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,386] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,387] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:37:17,395] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,401] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,469] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,470] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 78 ms (kafka.log.Log)
[2019-11-24 22:37:17,476] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,481] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,541] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,544] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:37:17,548] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,559] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,612] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,614] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 67 ms (kafka.log.Log)
[2019-11-24 22:37:17,617] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,636] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,696] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,705] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 89 ms (kafka.log.Log)
[2019-11-24 22:37:17,708] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,708] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,767] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,768] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:37:17,771] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,772] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,816] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,817] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 47 ms (kafka.log.Log)
[2019-11-24 22:37:17,821] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,821] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,877] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,878] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:17,882] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,882] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,948] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:17,950] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:37:17,953] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:17,954] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,048] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,049] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 98 ms (kafka.log.Log)
[2019-11-24 22:37:18,053] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,054] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,119] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,121] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:37:18,124] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,124] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,180] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,181] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:18,183] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,184] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,251] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,252] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:37:18,256] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,257] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,324] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,325] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 71 ms (kafka.log.Log)
[2019-11-24 22:37:18,329] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,329] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,384] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,385] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:37:18,388] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,389] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,445] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,446] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:18,449] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,449] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,506] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,507] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:18,510] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,510] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,519] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:18,577] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,578] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:18,579] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 71 ms (kafka.log.Log)
[2019-11-24 22:37:18,581] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,581] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,792] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:18,793] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 213 ms (kafka.log.Log)
[2019-11-24 22:37:18,796] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:18,796] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,061] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,062] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 268 ms (kafka.log.Log)
[2019-11-24 22:37:19,066] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,066] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,122] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,123] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:19,127] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,127] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,172] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,173] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 48 ms (kafka.log.Log)
[2019-11-24 22:37:19,176] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,176] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,233] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,234] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:19,237] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,237] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,294] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,295] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:19,297] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,298] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,353] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,354] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:37:19,357] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,358] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,414] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,416] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:19,419] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,419] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,475] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,476] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:19,479] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,479] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,537] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,538] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:37:19,540] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,540] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,597] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,598] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:19,600] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,601] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,658] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,659] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:19,662] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,662] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,719] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,720] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:19,722] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,723] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,734] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:19,780] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,780] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:19,782] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 61 ms (kafka.log.Log)
[2019-11-24 22:37:19,785] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,785] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,850] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,851] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:37:19,854] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,855] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,911] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,913] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:19,915] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,916] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,926] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:37:19,983] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:19,983] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:19,984] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 70 ms (kafka.log.Log)
[2019-11-24 22:37:19,992] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:19,992] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,043] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,044] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 54 ms (kafka.log.Log)
[2019-11-24 22:37:20,047] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,048] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,126] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,127] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 22:37:20,130] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,130] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,187] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,188] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:20,191] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,191] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,248] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,249] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:20,251] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,252] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,308] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,309] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:20,311] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,312] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,369] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,370] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:37:20,378] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:37:20,378] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,440] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:20,441] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 65 ms (kafka.log.Log)
[2019-11-24 22:37:20,444] INFO Logs loading complete in 4124 ms. (kafka.log.LogManager)
[2019-11-24 22:37:20,453] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:37:20,454] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:37:20,655] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:37:20,679] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:37:20,681] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:37:20,702] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,704] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,705] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,704] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,715] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:37:20,768] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:37:20,779] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410000 type:multi cxid:0x16 zxid:0xc2 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/0 Error:KeeperErrorCode = NodeExists for /brokers/ids/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:20,812] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72092140262785024' does not match current session '72092164334616576' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2019-11-24 22:37:20,817] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:122)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1784)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1722)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1689)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:97)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:262)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-24 22:37:20,819] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 22:37:20,820] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-24 22:37:20,824] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-24 22:37:20,828] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-24 22:37:20,829] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:37:20,830] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:37:20,830] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:37:20,830] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:37:20,831] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:37:20,832] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:37:20,834] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:37:20,834] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,906] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,906] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:20,907] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,104] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,104] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,106] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,308] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,308] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,309] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,510] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,510] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:21,513] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-24 22:37:21,514] INFO Shutting down. (kafka.log.LogManager)
[2019-11-24 22:37:22,013] INFO Expiring session 0x1001f6b6b760000, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:22,014] INFO Processed session termination for sessionid: 0x1001f6b6b760000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:22,892] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-24 22:37:22,892] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:22,894] INFO Processed session termination for sessionid: 0x1001f7106410000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:22,927] INFO Session: 0x1001f7106410000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:22,928] INFO Closed socket connection for client /127.0.0.1:54590 which had sessionid 0x1001f7106410000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:37:22,928] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:22,928] INFO EventThread shut down for session: 0x1001f7106410000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:22,930] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,261] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,261] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,262] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,284] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,284] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:23,286] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:24,285] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:24,285] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:24,288] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-24 22:37:24,303] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-24 22:37:24,308] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-24 22:37:24,309] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-24 22:37:24,311] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 22:37:34,061] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:37:34,455] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:37:34,456] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:37:34,473] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:34,476] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,476] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,477] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,477] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,478] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,478] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,481] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,483] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,483] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,485] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,486] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,486] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,487] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,487] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,487] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,489] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:37:34,504] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:34,507] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:34,509] INFO Accepted socket connection from /0:0:0:0:0:0:0:1:54630 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:37:34,509] INFO Socket connection established to localhost/0:0:0:0:0:0:0:1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:34,511] INFO Client attempting to establish new session at /0:0:0:0:0:0:0:1:54630 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:34,623] INFO Established session 0x1001f7106410001 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:54630 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:37:34,625] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1001f7106410001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:37:34,629] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:37:34,659] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x1 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,701] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x2 zxid:0xc7 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,733] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x3 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,764] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x4 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,809] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x5 zxid:0xca txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,839] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x6 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,867] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x7 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,894] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x8 zxid:0xcd txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,922] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0x9 zxid:0xce txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,950] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0xa zxid:0xcf txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:34,977] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0xb zxid:0xd0 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:35,005] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0xc zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:35,033] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:create cxid:0xd zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:35,154] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:37:35,197] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:37:35,208] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:37:35,234] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:35,235] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:35,236] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:37:35,262] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:37:35,389] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2610 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,402] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000002610.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:35,415] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 9 and log end offset 2610 in 130 ms (kafka.log.Log)
[2019-11-24 22:37:35,426] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,428] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,434] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,435] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,440] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,441] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,446] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,447] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,501] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,502] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:35,503] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 54 ms (kafka.log.Log)
[2019-11-24 22:37:35,561] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,563] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:35,564] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 59 ms (kafka.log.Log)
[2019-11-24 22:37:35,568] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,569] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,573] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,574] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,578] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,579] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,583] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,584] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,595] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,596] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 11 ms (kafka.log.Log)
[2019-11-24 22:37:35,601] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,602] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,606] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,606] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,610] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,611] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,615] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,616] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,620] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,620] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,624] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,625] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,629] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,629] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,635] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,636] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,640] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,640] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:37:35,644] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,645] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,650] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,650] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,654] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,654] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:37:35,658] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,658] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:37:35,662] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,664] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,721] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,722] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:35,723] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 58 ms (kafka.log.Log)
[2019-11-24 22:37:35,727] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,728] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,732] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,732] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,736] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,737] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,740] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,741] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,744] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,745] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,749] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,750] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,753] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,753] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:37:35,757] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,758] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,762] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,763] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,768] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,769] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:35,772] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,773] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,776] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,777] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,782] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,782] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,847] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,848] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:35,849] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 66 ms (kafka.log.Log)
[2019-11-24 22:37:35,852] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,853] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:35,856] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:35,857] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,221] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,222] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:37:36,222] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 363 ms (kafka.log.Log)
[2019-11-24 22:37:36,225] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,226] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,230] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,230] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,234] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,235] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,238] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,238] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2019-11-24 22:37:36,242] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,242] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,246] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,247] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:37:36,250] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:37:36,251] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:37:36,253] INFO Logs loading complete in 991 ms. (kafka.log.LogManager)
[2019-11-24 22:37:36,262] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:37:36,263] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:37:36,464] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:37:36,484] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:37:36,485] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:37:36,503] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,504] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,505] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,505] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,514] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:37:36,547] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:37:36,581] INFO Stat of the created znode at /brokers/ids/0 is: 211,211,1574656656553,1574656656553,1,0,0,72092164334616577,200,0,211
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:37:36,581] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 211 (kafka.zk.KafkaZkClient)
[2019-11-24 22:37:36,621] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,623] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,624] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:37:36,640] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:36,641] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:36,646] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:36,700] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:2000,blockEndProducerId:2999) by writing to Zk with path version 3 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:37:36,723] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:37:36,725] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:37:36,726] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:37:36,762] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:37:36,765] INFO Processing notification(s) to /config/changes (kafka.common.ZkNodeChangeNotificationListener)
[2019-11-24 22:37:36,772] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:37:36,778] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:37:36,782] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:37:36,783] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:37:36,788] INFO Processing override for entityPath: topics/testTopicName with config: Map(retention.ms -> 604800) (kafka.server.DynamicConfigManager)
[2019-11-24 22:37:36,794] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:37:36,794] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:37:36,795] INFO Kafka startTimeMs: 1574656656786 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:37:36,798] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:37:36,876] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:37:36,891] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:36,892] INFO Got user-level KeeperException when processing sessionid:0x1001f7106410001 type:multi cxid:0x7c zxid:0xd9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:37:36,896] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,044] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,045] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,111] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,112] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,161] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,161] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,210] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,211] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,282] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,282] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,342] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,343] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,403] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,404] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,464] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,464] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,514] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,514] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,563] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,564] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,613] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,614] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,675] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,675] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,724] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,724] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,784] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,784] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,835] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,836] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,894] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,895] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,944] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,944] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,993] INFO Replica loaded for partition testTopicName-0 with initial high watermark 2610 (kafka.cluster.Replica)
[2019-11-24 22:37:37,994] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 2610. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:37,997] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:37,997] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,043] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,043] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,093] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,094] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,143] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,143] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,203] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,203] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,253] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,253] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,303] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,303] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,352] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,352] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,402] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,403] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,480] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,480] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,544] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,544] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,623] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,623] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,684] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,684] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,722] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,723] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,772] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,773] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,821] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:37:38,822] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,824] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 22:37:38,824] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,827] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,827] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,882] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:37:38,882] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,885] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,886] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:38,943] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:38,944] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,004] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,004] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,054] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,054] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,114] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 1 (kafka.cluster.Replica)
[2019-11-24 22:37:39,115] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,117] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,117] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,164] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,164] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,217] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,218] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,265] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,265] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,423] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,423] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,653] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,653] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,721] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:37:39,721] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,770] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:37:39,770] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:37:39,775] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,776] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,777] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,778] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,779] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,780] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,782] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,782] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,782] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,784] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,784] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,784] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,785] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,787] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,788] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,789] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,789] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,790] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,791] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,792] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,793] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,794] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,795] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,796] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,797] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,797] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,798] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,799] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,800] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,813] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-44110 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:39,814] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 22 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,814] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,815] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,816] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,817] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,817] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,819] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,822] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-11308 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:39,827] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,832] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,832] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,833] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,837] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,838] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,839] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,840] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,840] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,841] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,841] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,841] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,842] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,843] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,843] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,843] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,846] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,848] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,848] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,851] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,852] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,852] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,853] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,855] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,855] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,855] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,856] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,856] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,856] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:37:39,886] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-81408 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member consumer-1-318444f6-b931-451f-89c8-cb73729fdac8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:39,891] INFO [GroupCoordinator 0]: Stabilized group console-consumer-81408 generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:39,899] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-81408 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:49,833] INFO [GroupCoordinator 0]: Member consumer-1-37316ab1-f9cc-4633-8bb0-27abaa0ffa62 in group console-consumer-11308 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:49,836] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-11308 in state PreparingRebalance with old generation 1 (__consumer_offsets-44) (reason: removing member consumer-1-37316ab1-f9cc-4633-8bb0-27abaa0ffa62 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:37:49,843] INFO [GroupCoordinator 0]: Group console-consumer-11308 with generation 2 is now empty (__consumer_offsets-44) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:38:39,233] WARN Exception causing close of session 0x1001f7106410001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:38:39,234] INFO Closed socket connection for client /0:0:0:0:0:0:0:1:54630 which had sessionid 0x1001f7106410001 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:38:58,664] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:38:58,667] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:38:58,668] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:38:58,668] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:38:58,668] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:38:58,684] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:38:58,685] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:38:58,692] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,692] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,692] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,693] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,693] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,693] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,697] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,706] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,706] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,706] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,706] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,707] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,707] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,707] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,707] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,722] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,722] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,723] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:58,740] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:38:58,742] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:38:58,844] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:38:59,359] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:38:59,362] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:38:59,376] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:38:59,379] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,380] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,380] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,380] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,380] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,380] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,384] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,386] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,389] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,390] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,391] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:38:59,409] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:38:59,412] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:38:59,417] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:38:59,419] INFO Accepted socket connection from /127.0.0.1:54705 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:38:59,424] INFO Client attempting to establish new session at /127.0.0.1:54705 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:59,425] INFO Creating new log file: log.db (org.apache.zookeeper.server.persistence.FileTxnLog)
[2019-11-24 22:38:59,465] INFO Established session 0x1001f729c310000 with negotiated timeout 6000 for client /127.0.0.1:54705 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:38:59,467] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f729c310000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:38:59,469] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:38:59,495] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x1 zxid:0xdc txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,533] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x2 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,563] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x3 zxid:0xde txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,591] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x4 zxid:0xdf txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,632] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x5 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,657] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x6 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,695] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x7 zxid:0xe2 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,724] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x8 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,762] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0x9 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,790] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0xa zxid:0xe5 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,828] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0xb zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,857] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0xc zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:38:59,895] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:create cxid:0xd zxid:0xe8 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:39:00,028] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:39:00,071] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:39:00,083] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:39:00,118] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:00,118] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:00,121] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:00,159] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:39:00,224] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 9 (kafka.log.Log)
[2019-11-24 22:39:00,226] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 9 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,269] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 9 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,368] INFO [ProducerStateManager partition=testTopicName-0] Writing producer snapshot at offset 2610 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,440] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2610 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,442] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000002610.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,450] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 9 and log end offset 2610 in 250 ms (kafka.log.Log)
[2019-11-24 22:39:00,462] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,462] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,578] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,579] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 119 ms (kafka.log.Log)
[2019-11-24 22:39:00,586] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,591] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,649] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,651] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-11-24 22:39:00,656] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,657] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,721] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,723] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:00,728] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,731] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,782] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,783] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:39:00,790] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,792] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,810] INFO [ProducerStateManager partition=__consumer_offsets-12] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,864] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,865] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,868] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 80 ms (kafka.log.Log)
[2019-11-24 22:39:00,880] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,880] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,911] INFO [ProducerStateManager partition=__consumer_offsets-13] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,969] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:00,970] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:00,973] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 96 ms (kafka.log.Log)
[2019-11-24 22:39:00,983] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:00,983] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,042] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,046] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 66 ms (kafka.log.Log)
[2019-11-24 22:39:01,055] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,056] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,112] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,115] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 63 ms (kafka.log.Log)
[2019-11-24 22:39:01,122] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,128] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,206] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,208] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 89 ms (kafka.log.Log)
[2019-11-24 22:39:01,212] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,215] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,267] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,268] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:39:01,273] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,276] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,339] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,341] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:01,345] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,345] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,410] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,411] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:39:01,416] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,417] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,429] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:01,483] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,485] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:01,491] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 78 ms (kafka.log.Log)
[2019-11-24 22:39:01,500] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,501] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,566] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,568] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:01,573] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,582] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,664] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,665] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 93 ms (kafka.log.Log)
[2019-11-24 22:39:01,669] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,673] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,725] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,726] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:39:01,729] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,730] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,786] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,787] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:39:01,792] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,796] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,846] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,847] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-24 22:39:01,853] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,855] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,918] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,919] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:01,922] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,927] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,990] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:01,991] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:39:01,994] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:01,999] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,060] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,061] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:39:02,066] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,071] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,144] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,145] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 22:39:02,153] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,156] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,217] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,220] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:39:02,226] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,237] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,298] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,299] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 74 ms (kafka.log.Log)
[2019-11-24 22:39:02,303] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,308] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,370] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,371] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:02,377] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,385] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,399] INFO [ProducerStateManager partition=__consumer_offsets-31] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:02,463] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,464] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:02,476] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 102 ms (kafka.log.Log)
[2019-11-24 22:39:02,496] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,496] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,568] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,569] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 79 ms (kafka.log.Log)
[2019-11-24 22:39:02,573] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,575] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,628] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,630] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:39:02,634] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,636] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,700] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,701] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:02,705] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,707] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,783] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,784] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 81 ms (kafka.log.Log)
[2019-11-24 22:39:02,788] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,790] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,855] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,856] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:39:02,863] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,864] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,916] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,917] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 56 ms (kafka.log.Log)
[2019-11-24 22:39:02,920] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:02,921] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,993] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:02,994] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-11-24 22:39:02,998] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,002] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,087] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,088] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-24 22:39:03,091] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,094] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,148] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,149] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 59 ms (kafka.log.Log)
[2019-11-24 22:39:03,153] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,156] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,242] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,243] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 91 ms (kafka.log.Log)
[2019-11-24 22:39:03,247] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,250] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,301] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,302] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 57 ms (kafka.log.Log)
[2019-11-24 22:39:03,306] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,308] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,363] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,364] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 60 ms (kafka.log.Log)
[2019-11-24 22:39:03,368] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,370] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,435] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,436] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 70 ms (kafka.log.Log)
[2019-11-24 22:39:03,442] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,444] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,463] INFO [ProducerStateManager partition=__consumer_offsets-44] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:03,517] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,518] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:03,520] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 81 ms (kafka.log.Log)
[2019-11-24 22:39:03,529] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,529] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,589] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,590] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-24 22:39:03,595] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,597] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,653] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,657] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 64 ms (kafka.log.Log)
[2019-11-24 22:39:03,670] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,671] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,692] INFO [ProducerStateManager partition=__consumer_offsets-47] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2019-11-24 22:39:03,755] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,756] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:39:03,759] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 93 ms (kafka.log.Log)
[2019-11-24 22:39:03,768] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,768] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,837] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,838] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 72 ms (kafka.log.Log)
[2019-11-24 22:39:03,841] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,845] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,897] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,898] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 58 ms (kafka.log.Log)
[2019-11-24 22:39:03,902] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,906] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,959] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:03,961] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 61 ms (kafka.log.Log)
[2019-11-24 22:39:03,969] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:03,982] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,041] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,042] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 75 ms (kafka.log.Log)
[2019-11-24 22:39:04,051] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:04,064] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,126] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,127] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 80 ms (kafka.log.Log)
[2019-11-24 22:39:04,131] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:04,137] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,196] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,198] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 69 ms (kafka.log.Log)
[2019-11-24 22:39:04,202] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Recovering unflushed segment 0 (kafka.log.Log)
[2019-11-24 22:39:04,209] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,268] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:39:04,268] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 68 ms (kafka.log.Log)
[2019-11-24 22:39:04,273] INFO Logs loading complete in 4114 ms. (kafka.log.LogManager)
[2019-11-24 22:39:04,291] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:39:04,292] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:39:04,528] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:39:04,554] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:39:04,556] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:39:04,583] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,586] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,587] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,586] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,614] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:39:04,699] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:39:04,710] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310000 type:multi cxid:0x16 zxid:0xe9 txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/brokers/ids/0 Error:KeeperErrorCode = NodeExists for /brokers/ids/0 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:39:04,740] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72092164334616577' does not match current session '72092171145117696' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2019-11-24 22:39:04,745] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:122)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1784)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1722)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1689)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:97)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:262)
	at kafka.server.KafkaServerStartable.startup(KafkaServerStartable.scala:38)
	at kafka.Kafka$.main(Kafka.scala:84)
	at kafka.Kafka.main(Kafka.scala)
[2019-11-24 22:39:04,749] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 22:39:04,755] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2019-11-24 22:39:04,762] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2019-11-24 22:39:04,789] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2019-11-24 22:39:04,792] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:39:04,794] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:39:04,794] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:39:04,797] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:39:04,821] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:39:04,826] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:39:04,832] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2019-11-24 22:39:04,852] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,989] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,989] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:04,998] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,184] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,184] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,186] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,197] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,197] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,198] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,394] INFO [ExpirationReaper-0-ElectPreferredLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,394] INFO [ExpirationReaper-0-ElectPreferredLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:39:05,409] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2019-11-24 22:39:05,412] INFO Shutting down. (kafka.log.LogManager)
[2019-11-24 22:39:06,862] INFO Shutdown complete. (kafka.log.LogManager)
[2019-11-24 22:39:06,863] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:39:06,865] INFO Processed session termination for sessionid: 0x1001f729c310000 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:39:06,896] INFO Session: 0x1001f729c310000 closed (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:39:06,897] INFO Closed socket connection for client /127.0.0.1:54705 which had sessionid 0x1001f729c310000 (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:39:06,897] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:39:06,897] INFO EventThread shut down for session: 0x1001f729c310000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:39:06,912] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:07,012] INFO Expiring session 0x1001f7106410001, timeout of 6000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:39:07,013] INFO Processed session termination for sessionid: 0x1001f7106410001 (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:39:07,122] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:07,122] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:07,131] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,127] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,127] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,129] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,156] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,156] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:39:08,158] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2019-11-24 22:39:08,213] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2019-11-24 22:39:08,221] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2019-11-24 22:39:08,232] ERROR Exiting Kafka. (kafka.server.KafkaServerStartable)
[2019-11-24 22:39:08,233] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2019-11-24 22:40:39,277] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2019-11-24 22:40:39,672] INFO starting (kafka.server.KafkaServer)
[2019-11-24 22:40:39,673] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2019-11-24 22:40:39,708] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:40:39,714] INFO Client environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,714] INFO Client environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,733] INFO Client environment:java.version=11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,757] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,759] INFO Client environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,782] INFO Client environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,809] INFO Client environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,817] INFO Client environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,818] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,837] INFO Client environment:os.name=Windows 10 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,839] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,839] INFO Client environment:os.version=10.0 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,847] INFO Client environment:user.name=dev (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,847] INFO Client environment:user.home=C:\Users\bitte (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,848] INFO Client environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,851] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@7b94089b (org.apache.zookeeper.ZooKeeper)
[2019-11-24 22:40:39,865] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:40:39,867] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:40:39,871] INFO Accepted socket connection from /127.0.0.1:54844 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:40:39,872] INFO Socket connection established to localhost/127.0.0.1:2181, initiating session (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:40:39,926] INFO Client attempting to establish new session at /127.0.0.1:54844 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:40:40,037] INFO Established session 0x1001f729c310001 with negotiated timeout 6000 for client /127.0.0.1:54844 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:40:40,038] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1001f729c310001, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2019-11-24 22:40:40,041] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2019-11-24 22:40:40,084] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x1 zxid:0xed txntype:-1 reqpath:n/a Error Path:/consumers Error:KeeperErrorCode = NodeExists for /consumers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,126] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x2 zxid:0xee txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,158] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x3 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics Error:KeeperErrorCode = NodeExists for /brokers/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,196] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x4 zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/config/changes Error:KeeperErrorCode = NodeExists for /config/changes (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,229] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x5 zxid:0xf1 txntype:-1 reqpath:n/a Error Path:/admin/delete_topics Error:KeeperErrorCode = NodeExists for /admin/delete_topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,263] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x6 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/seqid Error:KeeperErrorCode = NodeExists for /brokers/seqid (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,291] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x7 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/isr_change_notification Error:KeeperErrorCode = NodeExists for /isr_change_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,319] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x8 zxid:0xf4 txntype:-1 reqpath:n/a Error Path:/latest_producer_id_block Error:KeeperErrorCode = NodeExists for /latest_producer_id_block (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,347] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0x9 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/log_dir_event_notification Error:KeeperErrorCode = NodeExists for /log_dir_event_notification (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,374] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0xa zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,403] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0xb zxid:0xf7 txntype:-1 reqpath:n/a Error Path:/config/clients Error:KeeperErrorCode = NodeExists for /config/clients (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,430] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0xc zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/config/users Error:KeeperErrorCode = NodeExists for /config/users (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,458] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:create cxid:0xd zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/config/brokers Error:KeeperErrorCode = NodeExists for /config/brokers (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:40,604] INFO Cluster ID = puJvNzEITRuScebD0W0ReQ (kafka.server.KafkaServer)
[2019-11-24 22:40:40,653] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:40:40,667] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.3-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = null
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.3-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = [DEFAULT]
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2019-11-24 22:40:40,700] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:40:40,704] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:40:40,700] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2019-11-24 22:40:40,737] INFO Loading logs. (kafka.log.LogManager)
[2019-11-24 22:40:40,867] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 2610 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:40,878] INFO [ProducerStateManager partition=testTopicName-0] Loading producer state from snapshot file 'D:\tmp\kafka-logs\testTopicName-0\00000000000000002610.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:40,894] INFO [Log partition=testTopicName-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 9 and log end offset 2610 in 130 ms (kafka.log.Log)
[2019-11-24 22:40:40,907] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:40,909] INFO [Log partition=__consumer_offsets-0, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:40,925] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:40,925] INFO [Log partition=__consumer_offsets-1, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:40:40,935] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:40,936] INFO [Log partition=__consumer_offsets-10, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:40,960] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:40,961] INFO [Log partition=__consumer_offsets-11, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,035] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,036] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-12\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,038] INFO [Log partition=__consumer_offsets-12, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 55 ms (kafka.log.Log)
[2019-11-24 22:40:41,107] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,108] INFO [ProducerStateManager partition=__consumer_offsets-13] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-13\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,110] INFO [Log partition=__consumer_offsets-13, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 63 ms (kafka.log.Log)
[2019-11-24 22:40:41,123] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,141] INFO [Log partition=__consumer_offsets-14, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:40:41,146] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,148] INFO [Log partition=__consumer_offsets-15, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:40:41,157] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,169] INFO [Log partition=__consumer_offsets-16, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 15 ms (kafka.log.Log)
[2019-11-24 22:40:41,176] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,181] INFO [Log partition=__consumer_offsets-17, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-24 22:40:41,186] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,192] INFO [Log partition=__consumer_offsets-18, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-24 22:40:41,197] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,203] INFO [Log partition=__consumer_offsets-19, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 8 ms (kafka.log.Log)
[2019-11-24 22:40:41,269] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Loading producer state till offset 1 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,275] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-2\00000000000000000001.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,279] INFO [Log partition=__consumer_offsets-2, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 1 in 71 ms (kafka.log.Log)
[2019-11-24 22:40:41,291] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,298] INFO [Log partition=__consumer_offsets-20, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 14 ms (kafka.log.Log)
[2019-11-24 22:40:41,306] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,309] INFO [Log partition=__consumer_offsets-21, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-24 22:40:41,315] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,317] INFO [Log partition=__consumer_offsets-22, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:40:41,326] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,327] INFO [Log partition=__consumer_offsets-23, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,332] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,346] INFO [Log partition=__consumer_offsets-24, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 17 ms (kafka.log.Log)
[2019-11-24 22:40:41,350] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,356] INFO [Log partition=__consumer_offsets-25, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 9 ms (kafka.log.Log)
[2019-11-24 22:40:41,360] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,364] INFO [Log partition=__consumer_offsets-26, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 7 ms (kafka.log.Log)
[2019-11-24 22:40:41,370] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,371] INFO [Log partition=__consumer_offsets-27, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,395] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,396] INFO [Log partition=__consumer_offsets-28, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,402] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,421] INFO [Log partition=__consumer_offsets-29, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-24 22:40:41,426] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,444] INFO [Log partition=__consumer_offsets-3, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 21 ms (kafka.log.Log)
[2019-11-24 22:40:41,449] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,453] INFO [Log partition=__consumer_offsets-30, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:40:41,513] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,515] INFO [ProducerStateManager partition=__consumer_offsets-31] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-31\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,526] INFO [Log partition=__consumer_offsets-31, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 71 ms (kafka.log.Log)
[2019-11-24 22:40:41,531] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,531] INFO [Log partition=__consumer_offsets-32, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:40:41,542] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,543] INFO [Log partition=__consumer_offsets-33, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:40:41,574] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,586] INFO [Log partition=__consumer_offsets-34, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 19 ms (kafka.log.Log)
[2019-11-24 22:40:41,591] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,592] INFO [Log partition=__consumer_offsets-35, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,596] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,597] INFO [Log partition=__consumer_offsets-36, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,602] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,621] INFO [Log partition=__consumer_offsets-37, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-24 22:40:41,627] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,628] INFO [Log partition=__consumer_offsets-38, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:40:41,653] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,654] INFO [Log partition=__consumer_offsets-39, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:40:41,678] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,679] INFO [Log partition=__consumer_offsets-4, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,685] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,705] INFO [Log partition=__consumer_offsets-40, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 24 ms (kafka.log.Log)
[2019-11-24 22:40:41,710] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,729] INFO [Log partition=__consumer_offsets-41, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 22 ms (kafka.log.Log)
[2019-11-24 22:40:41,736] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,756] INFO [Log partition=__consumer_offsets-42, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-24 22:40:41,762] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,762] INFO [Log partition=__consumer_offsets-43, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:40:41,817] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Loading producer state till offset 2 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,818] INFO [ProducerStateManager partition=__consumer_offsets-44] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-44\00000000000000000002.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,823] INFO [Log partition=__consumer_offsets-44, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 2 in 51 ms (kafka.log.Log)
[2019-11-24 22:40:41,846] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,846] INFO [Log partition=__consumer_offsets-45, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2019-11-24 22:40:41,850] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,870] INFO [Log partition=__consumer_offsets-46, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 23 ms (kafka.log.Log)
[2019-11-24 22:40:41,922] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Loading producer state till offset 3 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,923] INFO [ProducerStateManager partition=__consumer_offsets-47] Loading producer state from snapshot file 'D:\tmp\kafka-logs\__consumer_offsets-47\00000000000000000003.snapshot' (kafka.log.ProducerStateManager)
[2019-11-24 22:40:41,925] INFO [Log partition=__consumer_offsets-47, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 3 in 51 ms (kafka.log.Log)
[2019-11-24 22:40:41,936] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,959] INFO [Log partition=__consumer_offsets-48, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms (kafka.log.Log)
[2019-11-24 22:40:41,965] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,966] INFO [Log partition=__consumer_offsets-49, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:41,989] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:41,991] INFO [Log partition=__consumer_offsets-5, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:40:42,019] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:42,020] INFO [Log partition=__consumer_offsets-6, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 6 ms (kafka.log.Log)
[2019-11-24 22:40:42,045] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:42,047] INFO [Log partition=__consumer_offsets-7, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 5 ms (kafka.log.Log)
[2019-11-24 22:40:42,074] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:42,075] INFO [Log partition=__consumer_offsets-8, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[2019-11-24 22:40:42,101] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2019-11-24 22:40:42,110] INFO [Log partition=__consumer_offsets-9, dir=D:\tmp\kafka-logs] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 12 ms (kafka.log.Log)
[2019-11-24 22:40:42,118] INFO Logs loading complete in 1381 ms. (kafka.log.LogManager)
[2019-11-24 22:40:42,129] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2019-11-24 22:40:42,138] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2019-11-24 22:40:42,361] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2019-11-24 22:40:42,383] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2019-11-24 22:40:42,385] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2019-11-24 22:40:42,410] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,411] INFO [ExpirationReaper-0-ElectPreferredLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,411] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,410] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,435] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2019-11-24 22:40:42,463] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2019-11-24 22:40:42,504] INFO Stat of the created znode at /brokers/ids/0 is: 250,250,1574656842471,1574656842471,1,0,0,72092171145117697,200,0,250
 (kafka.zk.KafkaZkClient)
[2019-11-24 22:40:42,505] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(DESKTOP-I5TC5S3,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 250 (kafka.zk.KafkaZkClient)
[2019-11-24 22:40:42,555] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,557] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,557] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2019-11-24 22:40:42,576] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:42,580] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:42,586] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:42,941] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:3000,blockEndProducerId:3999) by writing to Zk with path version 4 (kafka.coordinator.transaction.ProducerIdManager)
[2019-11-24 22:40:42,979] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:40:42,982] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2019-11-24 22:40:42,995] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2019-11-24 22:40:43,027] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2019-11-24 22:40:43,058] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2019-11-24 22:40:43,072] INFO Kafka version: 2.3.1 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:40:43,072] INFO Kafka commitId: 18a913733fb71c01 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:40:43,088] INFO Kafka startTimeMs: 1574656843063 (org.apache.kafka.common.utils.AppInfoParser)
[2019-11-24 22:40:43,092] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2019-11-24 22:40:43,159] INFO Got user-level KeeperException when processing sessionid:0x1001f729c310001 type:multi cxid:0x6a zxid:0xfd txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election (org.apache.zookeeper.server.PrepRequestProcessor)
[2019-11-24 22:40:43,170] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, testTopicName-0, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2019-11-24 22:40:43,203] INFO Replica loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,208] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,274] INFO Replica loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,274] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,344] INFO Replica loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,345] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,415] INFO Replica loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,416] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,489] INFO Replica loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,490] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,550] INFO Replica loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,551] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,630] INFO Replica loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,631] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,702] INFO Replica loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,702] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,773] INFO Replica loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,773] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,824] INFO Replica loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,824] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,880] INFO Replica loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,880] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:43,951] INFO Replica loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:43,951] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,011] INFO Replica loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,011] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,079] INFO Replica loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,080] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,144] INFO Replica loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,145] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,205] INFO Replica loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,205] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,265] INFO Replica loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,266] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,326] INFO Replica loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,326] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,387] INFO Replica loaded for partition testTopicName-0 with initial high watermark 2610 (kafka.cluster.Replica)
[2019-11-24 22:40:44,388] INFO [Partition testTopicName-0 broker=0] testTopicName-0 starts at Leader Epoch 0 from offset 2610. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,392] INFO Replica loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,404] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,458] INFO Replica loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,458] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,520] INFO Replica loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,520] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,580] INFO Replica loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,580] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,632] INFO Replica loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:44,632] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:44,999] INFO Replica loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,000] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,052] INFO Replica loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,052] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,113] INFO Replica loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,114] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,173] INFO Replica loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,173] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,245] INFO Replica loaded for partition __consumer_offsets-2 with initial high watermark 1 (kafka.cluster.Replica)
[2019-11-24 22:40:45,247] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 1. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,266] INFO Replica loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,267] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,345] INFO Replica loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,345] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,406] INFO Replica loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,406] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,455] INFO Replica loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,455] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,523] INFO Replica loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,525] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,605] INFO Replica loaded for partition __consumer_offsets-12 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:40:45,605] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,610] INFO Replica loaded for partition __consumer_offsets-31 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 22:40:45,615] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,622] INFO Replica loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,623] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,720] INFO Replica loaded for partition __consumer_offsets-47 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:40:45,721] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,724] INFO Replica loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,730] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,792] INFO Replica loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,792] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,854] INFO Replica loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,855] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,916] INFO Replica loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:45,916] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,985] INFO Replica loaded for partition __consumer_offsets-44 with initial high watermark 2 (kafka.cluster.Replica)
[2019-11-24 22:40:45,986] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at Leader Epoch 0 from offset 2. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:45,990] INFO Replica loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,000] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,051] INFO Replica loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,052] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,106] INFO Replica loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,107] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,166] INFO Replica loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,167] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,227] INFO Replica loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,227] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,289] INFO Replica loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,290] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,362] INFO Replica loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Replica)
[2019-11-24 22:40:46,363] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,416] INFO Replica loaded for partition __consumer_offsets-13 with initial high watermark 3 (kafka.cluster.Replica)
[2019-11-24 22:40:46,417] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at Leader Epoch 0 from offset 3. Previous Leader Epoch was: -1 (kafka.cluster.Partition)
[2019-11-24 22:40:46,438] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,446] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,458] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,472] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,474] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,474] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,489] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,493] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,508] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,512] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,534] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-44110 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:46,534] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,538] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 27 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,561] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,565] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,575] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,598] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,627] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,651] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,655] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,655] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,675] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,678] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,678] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,694] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,697] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,718] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,719] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,719] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-11308 with generation 2 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:46,727] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,729] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 13 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,730] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,758] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,758] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,783] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,786] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,786] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,806] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,808] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,821] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,824] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,845] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,848] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,873] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,875] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,894] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,897] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,914] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,916] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,942] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,946] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,949] INFO [GroupCoordinator 0]: Loading group metadata for console-consumer-81408 with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:46,965] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,975] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 30 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,986] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:46,989] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,006] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,010] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,027] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,051] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,054] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,055] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,076] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,079] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,080] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,096] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,110] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,115] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,116] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,129] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,152] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,157] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,162] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,179] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,192] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,192] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,203] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,204] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,214] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,216] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,217] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,223] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,224] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,226] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,227] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,238] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,245] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,259] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,274] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,279] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,293] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,296] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,297] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,315] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-8622 in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member consumer-1-043559b5-057c-45c0-bb54-4f55bdef3954 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:47,316] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,321] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,340] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,341] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,342] INFO [GroupCoordinator 0]: Stabilized group console-consumer-8622 generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:47,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,365] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2019-11-24 22:40:47,373] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-8622 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:56,978] INFO [GroupCoordinator 0]: Member consumer-1-318444f6-b931-451f-89c8-cb73729fdac8 in group console-consumer-81408 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:56,979] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-81408 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member consumer-1-318444f6-b931-451f-89c8-cb73729fdac8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:40:56,981] INFO [GroupCoordinator 0]: Group console-consumer-81408 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:19,806] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:41:19,810] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:41:19,810] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:41:19,810] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:41:19,810] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:41:19,844] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:41:19,846] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:41:19,866] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,866] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,867] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,867] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,867] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,867] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,870] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,872] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,873] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,874] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,882] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,882] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,882] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:41:19,914] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:41:19,916] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:41:19,919] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:461)
	at java.base/sun.nio.ch.Net.bind(Net.java:453)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-11-24 22:41:20,496] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-22686 in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member consumer-1-a888b934-adf2-49c8-8d67-e02a716a26ec with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:20,497] INFO [GroupCoordinator 0]: Stabilized group console-consumer-22686 generation 1 (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:20,503] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-22686 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:30,512] INFO [GroupCoordinator 0]: Member consumer-1-a888b934-adf2-49c8-8d67-e02a716a26ec in group console-consumer-22686 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:30,512] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-22686 in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: removing member consumer-1-a888b934-adf2-49c8-8d67-e02a716a26ec on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:41:30,515] INFO [GroupCoordinator 0]: Group console-consumer-22686 with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)
[2019-11-24 22:42:15,074] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:42:15,076] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:42:15,076] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:42:15,077] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2019-11-24 22:42:15,077] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2019-11-24 22:42:15,091] INFO Reading configuration from: config\zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2019-11-24 22:42:15,092] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2019-11-24 22:42:15,098] INFO Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,099] INFO Server environment:host.name=DESKTOP-I5TC5S3 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,099] INFO Server environment:java.version=11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,099] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,099] INFO Server environment:java.home=C:\Program Files\Java\jdk-11.0.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,099] INFO Server environment:java.class.path=D:\k\k2.3.1\libs\activation-1.1.1.jar;D:\k\k2.3.1\libs\aopalliance-repackaged-2.5.0.jar;D:\k\k2.3.1\libs\argparse4j-0.7.0.jar;D:\k\k2.3.1\libs\audience-annotations-0.5.0.jar;D:\k\k2.3.1\libs\commons-lang3-3.8.1.jar;D:\k\k2.3.1\libs\connect-api-2.3.1.jar;D:\k\k2.3.1\libs\connect-basic-auth-extension-2.3.1.jar;D:\k\k2.3.1\libs\connect-file-2.3.1.jar;D:\k\k2.3.1\libs\connect-json-2.3.1.jar;D:\k\k2.3.1\libs\connect-runtime-2.3.1.jar;D:\k\k2.3.1\libs\connect-transforms-2.3.1.jar;D:\k\k2.3.1\libs\guava-20.0.jar;D:\k\k2.3.1\libs\hk2-api-2.5.0.jar;D:\k\k2.3.1\libs\hk2-locator-2.5.0.jar;D:\k\k2.3.1\libs\hk2-utils-2.5.0.jar;D:\k\k2.3.1\libs\jackson-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-core-2.10.0.jar;D:\k\k2.3.1\libs\jackson-databind-2.10.0.jar;D:\k\k2.3.1\libs\jackson-dataformat-csv-2.10.0.jar;D:\k\k2.3.1\libs\jackson-datatype-jdk8-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-base-2.10.0.jar;D:\k\k2.3.1\libs\jackson-jaxrs-json-provider-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-jaxb-annotations-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-paranamer-2.10.0.jar;D:\k\k2.3.1\libs\jackson-module-scala_2.12-2.10.0.jar;D:\k\k2.3.1\libs\jakarta.activation-api-1.2.1.jar;D:\k\k2.3.1\libs\jakarta.annotation-api-1.3.4.jar;D:\k\k2.3.1\libs\jakarta.inject-2.5.0.jar;D:\k\k2.3.1\libs\jakarta.ws.rs-api-2.1.5.jar;D:\k\k2.3.1\libs\jakarta.xml.bind-api-2.3.2.jar;D:\k\k2.3.1\libs\javassist-3.22.0-CR2.jar;D:\k\k2.3.1\libs\javax.servlet-api-3.1.0.jar;D:\k\k2.3.1\libs\javax.ws.rs-api-2.1.1.jar;D:\k\k2.3.1\libs\jaxb-api-2.3.0.jar;D:\k\k2.3.1\libs\jersey-client-2.28.jar;D:\k\k2.3.1\libs\jersey-common-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-2.28.jar;D:\k\k2.3.1\libs\jersey-container-servlet-core-2.28.jar;D:\k\k2.3.1\libs\jersey-hk2-2.28.jar;D:\k\k2.3.1\libs\jersey-media-jaxb-2.28.jar;D:\k\k2.3.1\libs\jersey-server-2.28.jar;D:\k\k2.3.1\libs\jetty-client-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-continuation-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-http-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-io-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-security-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-server-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlet-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-servlets-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jetty-util-9.4.18.v20190429.jar;D:\k\k2.3.1\libs\jopt-simple-5.0.4.jar;D:\k\k2.3.1\libs\jsr305-3.0.2.jar;D:\k\k2.3.1\libs\kafka-clients-2.3.1.jar;D:\k\k2.3.1\libs\kafka-log4j-appender-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-examples-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-scala_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka-streams-test-utils-2.3.1.jar;D:\k\k2.3.1\libs\kafka-tools-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-javadoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-scaladoc.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test-sources.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1-test.jar.asc;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar;D:\k\k2.3.1\libs\kafka_2.12-2.3.1.jar.asc;D:\k\k2.3.1\libs\log4j-1.2.17.jar;D:\k\k2.3.1\libs\lz4-java-1.6.0.jar;D:\k\k2.3.1\libs\maven-artifact-3.6.1.jar;D:\k\k2.3.1\libs\metrics-core-2.2.0.jar;D:\k\k2.3.1\libs\osgi-resource-locator-1.0.1.jar;D:\k\k2.3.1\libs\paranamer-2.8.jar;D:\k\k2.3.1\libs\plexus-utils-3.2.0.jar;D:\k\k2.3.1\libs\reflections-0.9.11.jar;D:\k\k2.3.1\libs\rocksdbjni-5.18.3.jar;D:\k\k2.3.1\libs\scala-library-2.12.10.jar;D:\k\k2.3.1\libs\scala-library-2.12.8.jar;D:\k\k2.3.1\libs\scala-logging_2.12-3.9.0.jar;D:\k\k2.3.1\libs\scala-reflect-2.12.8.jar;D:\k\k2.3.1\libs\slf4j-api-1.7.26.jar;D:\k\k2.3.1\libs\slf4j-log4j12-1.7.26.jar;D:\k\k2.3.1\libs\snappy-java-1.1.7.3.jar;D:\k\k2.3.1\libs\spotbugs-annotations-3.1.9.jar;D:\k\k2.3.1\libs\validation-api-2.0.1.Final.jar;D:\k\k2.3.1\libs\zkclient-0.11.jar;D:\k\k2.3.1\libs\zookeeper-3.4.14.jar;D:\k\k2.3.1\libs\zstd-jni-1.4.0-1.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,101] INFO Server environment:java.library.path=C:\Program Files\Java\jdk-11.0.1\bin;C:\WINDOWS\Sun\Java\bin;C:\WINDOWS\system32;C:\WINDOWS;C:\Program Files\Python37\Scripts\;C:\Program Files\Python37\;C:\Program Files\apache-maven-3.5.4\bin;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Program Files\Git LFS;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Java\jdk-11.0.1\bin;C:\Program Files\Mercurial\;C:\Program Files\Microsoft SQL Server\130\Tools\Binn\;C:\Program Files\Microsoft SQL Server\140\DTS\Binn\;C:\Program Files\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\130\Tools\Binn\;C:\Program Files\nodejs\;C:\Program Files\NVIDIA Corporation\cuda\bin;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.0\libnvvp;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Microsoft SQL Server\140\Tools\Binn\;C:\Program Files (x86)\Microsoft SQL Server\150\DTS\Binn\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Users\bitte\.gradle;C:\Users\bitte\AppData\Local\Android\Sdk\;C:\Users\bitte\AppData\Local\Android\Sdk\emulator\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Windows;C:\Windows\system32;C:\WINDOWS\System32\OpenSSH\;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\cmd;C:\Program Files (x86)\Yarn\bin\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Users\bitte\.windows-build-tools\python27\;C:\Program Files\nodejs\node_modules\npm\node_modules\npm-lifecycle\node-gyp-bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\windows-build-tools\node_modules\.bin;C:\Users\bitte\AppData\Roaming\npm\node_modules\.bin;C:\Program Files (x86)\Common Files\Oracle\Java\javapath;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\iCLS\;C:\Program Files\Intel\Intel(R) Management Engine Components\iCLS\;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files\Intel\Intel(R) Management Engine Components\DAL;C:\Program Files (x86)\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files\Intel\Intel(R) Management Engine Components\IPT;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Intel\WiFi\bin\;C:\Program Files\Common Files\Intel\WirelessCommon\;C:\Program Files\dotnet\;C:\Users\bitte\AppData\Local\Android\Sdk\platform-tools\;C:\Program Files\nodejs\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\cmd;C:\Users\bitte\AppData\Local\Atlassian\SourceTree\git_local\bin;C:\Program Files\Mercurial\;C:\Program Files\apache-maven-3.5.4\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;C:\Users\bitte\AppData\Roaming\npm;C:\Users\bitte\AppData\Local\atom\bin;C:\Users\bitte\AppData\Local\Microsoft\WindowsApps;;C:\Users\bitte\AppData\Local\Programs\Microsoft VS Code\bin;C:\Users\bitte\.dotnet\tools;C:\Users\bitte\AppData\Local\Yarn\bin;. (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,107] INFO Server environment:java.io.tmpdir=C:\Users\bitte\AppData\Local\Temp\ (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,107] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,107] INFO Server environment:os.name=Windows 10 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,107] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,108] INFO Server environment:os.version=10.0 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,108] INFO Server environment:user.name=dev (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,108] INFO Server environment:user.home=C:\Users\bitte (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,108] INFO Server environment:user.dir=D:\k\k2.3.1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,122] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,125] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,125] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2019-11-24 22:42:15,145] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2019-11-24 22:42:15,148] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2019-11-24 22:42:15,149] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use: bind
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:461)
	at java.base/sun.nio.ch.Net.bind(Net.java:453)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:90)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:120)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:89)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:55)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:119)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:81)
[2019-11-24 22:42:29,716] WARN Exception causing close of session 0x1001f729c310001: An existing connection was forcibly closed by the remote host (org.apache.zookeeper.server.NIOServerCnxn)
[2019-11-24 22:42:29,716] INFO Closed socket connection for client /127.0.0.1:54844 which had sessionid 0x1001f729c310001 (org.apache.zookeeper.server.NIOServerCnxn)
